{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUFUVVL0rb3h"
      },
      "source": [
        "MNIST TRAINING DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8j2HzYkQrb3i"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "11.8\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.cuda\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "print(torch.version.cuda)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDXmSEDpGFfF"
      },
      "source": [
        "Initialize before every new learning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "Enq05hoFrb3j",
        "outputId": "cd97e554-f8c1-45cb-a1b9-545a308728ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n",
            "device\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 9 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available()else 'cpu')\n",
        "print(device)\n",
        "print(torch.device.__name__)\n",
        "\n",
        "#hyperparameters\n",
        "input_size = 784\n",
        "hidden_size = 500\n",
        "num_classes = 10\n",
        "num_epochs = 10\n",
        "batch_size = 100\n",
        "learning_rate = 0.01\n",
        "\n",
        "#MNIST\n",
        "train_dataset = torchvision.datasets.MNIST(root='../myneuralnetworks/datasets',train=True,transform=transforms.ToTensor(),download=True)\n",
        "test_dataset = torchvision.datasets.MNIST(root='../myneuralnetworks/datasets',train=False,transform=transforms.ToTensor())\n",
        "\n",
        "#train loader \n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,batch_size=batch_size,shuffle=True)\n",
        "\n",
        "#test loader\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,batch_size=batch_size,shuffle=False)\n",
        "\n",
        "#examples\n",
        "examples = iter(train_loader)\n",
        "samples,labels = next(examples)\n",
        "# print(samples,labels)\n",
        "# print(samples.shape,labels.shape)\n",
        "for i in range(9):\n",
        "    plt.subplot(3,3,i+1) #3 rows 3 columns and i is index of the subplot\n",
        "    plt.imshow(samples[i][0], cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvHpIjw95UJw"
      },
      "source": [
        "Creating a model with different linearities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_B013ub9UdL"
      },
      "outputs": [],
      "source": [
        "\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.l1 = nn.Linear(input_size, hidden_size) \n",
        "        self.relu = nn.ReLU()\n",
        "        self.tanh = nn.Tanh()\n",
        "        self.sigmoid =nn.Sigmoid()\n",
        "\n",
        "        self.l2 = nn.Linear(hidden_size, num_classes)  \n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.l1(x)\n",
        "        # out =self.tanh(out)\n",
        "        # out =self.sigmoid(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.l2(out)\n",
        "        # no activation and no softmax at the end\n",
        "        return out\n",
        "\n",
        "model = NeuralNet(input_size, hidden_size, num_classes).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhVmBH2F7v8f"
      },
      "source": [
        "training a model with different optimizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGGJDhVQrb3l",
        "outputId": "58268db4-2a5e-4a2d-e940-bcbc356b734b"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "optimizer2 = torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
        "loss =nn.CrossEntropyLoss()\n",
        "totalsteps=len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i,(images,labels) in enumerate(train_loader):\n",
        "        images = images.reshape(-1,28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "        #forward pass\n",
        "        output=model(images)\n",
        "        l = loss(output,labels)\n",
        "        #backward pass\n",
        "        optimizer.zero_grad()\n",
        "        l.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5, 2.0)\n",
        "        optimizer.step()\n",
        "        if(epoch%5==0):\n",
        "            learning_rate =learning_rate*0.1\n",
        "            optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "            \n",
        "        if (i+1)%100==0:\n",
        "            print(f'epoch {epoch+1}/{num_epochs}, step {i+1}/{totalsteps}, loss={l.item():.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6-ObVZG7zsp",
        "outputId": "ec374e30-0f31-4139-f2e2-f8eb5c237897"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "optimizer2 = torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
        "loss =nn.CrossEntropyLoss()\n",
        "totalsteps=len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i,(images,labels) in enumerate(train_loader):\n",
        "        images = images.reshape(-1,28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "        #forward pass\n",
        "        output=model(images)\n",
        "        l = loss(output,labels)\n",
        "        #backward pass\n",
        "        optimizer2.zero_grad()\n",
        "        l.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5, 2.0)\n",
        "        optimizer2.step()\n",
        "        if (i+1)%100==0:\n",
        "            print(f'epoch {epoch+1}/{num_epochs}, step {i+1}/{totalsteps}, loss={l.item():.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eB104PC35XV4"
      },
      "source": [
        "Test the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bghAuF-I1lM",
        "outputId": "821fef19-bd97-49d0-82b7-11bad3df7557"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    correct=0;\n",
        "    examples =len(test_loader.dataset)\n",
        "    for images,labels in test_loader:\n",
        "        images = images.reshape(-1,28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "        output = model(images)\n",
        "    \n",
        "     # max returns (output_value ,index)\n",
        "        _, predicted = torch.max(output, 1)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    acc = correct / examples\n",
        "    print(f'Accuracy of the network on the {examples} test images: {100*acc} %')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_niCvc88N-5"
      },
      "source": [
        "CNN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NVIDIA GeForce MX150\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(torch.cuda.get_device_name())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [],
      "source": [
        "#HyperParameters\n",
        "num_classes = 10\n",
        "num_epochs = 10\n",
        "batch_size = 100\n",
        "learning_rate = 0.01"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [],
      "source": [
        "#transform image to tensor\n",
        "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.1307,), (0.3081,))])\n",
        "#MNIST\n",
        "train_dataset = torchvision.datasets.MNIST(root='../myneuralnetworks/datasets',train=True,transform=transforms.ToTensor(),download=True)\n",
        "test_dataset = torchvision.datasets.MNIST(root='../myneuralnetworks/datasets',train=False,transform=transforms.ToTensor())\n",
        "\n",
        "#train loader \n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,batch_size=batch_size,shuffle=True)\n",
        "\n",
        "#test loader\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,batch_size=batch_size,shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<torch.utils.data.dataloader.DataLoader object at 0x0000027844D6B2B0>\n"
          ]
        }
      ],
      "source": [
        "print(train_loader)\n",
        "dataiter= iter(train_loader)\n",
        "images,labels = next(dataiter)\n",
        "# print(images.shape)\n",
        "# print(images[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [],
      "source": [
        "class convolutionalNet(nn.Module):\n",
        "    def __init__(self): \n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5) \n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.maxpool = nn.MaxPool2d(2,2)\n",
        "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "        self.relu =nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x= self.conv1(x) # N 28,24,24\n",
        "        x= self.relu(x) \n",
        "        x= self.maxpool(x) # N 28, 12,12 \n",
        "        x= self.conv2(x)\n",
        "        x= self.relu(x)\n",
        "        x= self.maxpool(x)\n",
        "        x= x.view(-1,16*4*4)\n",
        "        x= self.fc1(x)\n",
        "        x= self.relu(x)\n",
        "        x= self.fc2(x)\n",
        "        x= self.relu(x)\n",
        "        x= self.fc3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "conv1.weight\n",
            "Parameter containing:\n",
            "tensor([[[[ 0.0829, -0.1036, -0.3052, -0.5707, -0.3004],\n",
            "          [-0.2435,  0.0044,  0.2659, -0.4390, -1.0221],\n",
            "          [-0.0650,  0.3002,  0.9762,  0.5781, -0.2031],\n",
            "          [-0.2079, -0.4764,  0.3041,  0.1879, -0.1927],\n",
            "          [-0.4431, -0.2428, -0.1558,  0.3696,  0.0712]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1078,  0.1490,  0.5940,  0.3468,  0.3099],\n",
            "          [-0.1155,  0.1904, -0.0660, -0.2478, -0.6830],\n",
            "          [ 0.4485,  0.3503, -0.2724, -1.1439, -0.6110],\n",
            "          [-0.0484,  0.1982, -0.5636, -1.5694, -0.2568],\n",
            "          [-0.0787, -0.2571, -0.2860, -0.8013, -0.2909]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2543, -0.0773, -1.2183, -0.2073,  0.2095],\n",
            "          [-0.2401, -1.1922, -0.5605,  0.4278,  0.4278],\n",
            "          [-0.5741, -0.2549,  0.2302,  0.0126,  0.2093],\n",
            "          [-0.3954, -0.1653,  0.1852, -0.0559,  0.2463],\n",
            "          [-0.4270,  0.0533,  0.0108,  0.1796,  0.4499]]],\n",
            "\n",
            "\n",
            "        [[[-0.5887, -0.5128,  0.3931,  0.6842,  0.0843],\n",
            "          [-0.7297, -1.0207, -2.4910, -1.0869, -1.1021],\n",
            "          [-0.3426, -0.1226, -0.2330, -0.5391, -0.6331],\n",
            "          [ 0.1638,  0.2516,  0.1927,  0.2226,  0.0835],\n",
            "          [ 0.3067,  0.3068, -0.0429,  0.4288,  0.3117]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1287, -0.1996, -0.1736,  0.3695,  0.1801],\n",
            "          [ 0.1014,  0.0521,  0.2025,  0.5087,  0.1613],\n",
            "          [-0.0115,  0.4505,  0.2528,  0.5861,  0.3362],\n",
            "          [-0.6430, -0.5062, -0.5253, -0.0430,  0.0965],\n",
            "          [-1.0457, -1.0337, -1.3515, -0.8799, -0.2658]]],\n",
            "\n",
            "\n",
            "        [[[ 0.9642, -0.3841, -0.4827,  0.0618, -0.1433],\n",
            "          [-0.1507, -1.8834, -0.3562,  0.1797,  0.1943],\n",
            "          [-0.1085, -0.0691,  0.9012,  0.3667, -0.1365],\n",
            "          [ 0.1588,  0.4372,  0.0877, -0.4405, -0.1377],\n",
            "          [ 0.1490, -0.2139, -0.2548, -0.3340, -0.1855]]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "conv1.bias\n",
            "Parameter containing:\n",
            "tensor([-0.4266, -0.2787, -0.2594, -0.0790, -0.1384, -1.0090], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "conv2.weight\n",
            "Parameter containing:\n",
            "tensor([[[[ 5.1173e-01, -1.5777e+00,  9.1177e-02,  6.3751e-01,  2.7404e-01],\n",
            "          [-3.0190e-01, -1.0013e+00,  3.6888e-01,  1.5820e-01,  2.0783e-01],\n",
            "          [-2.4250e-01, -1.3604e-01,  2.8868e-01, -3.1433e-01, -8.4560e-01],\n",
            "          [-1.3053e-02, -2.2613e-01, -3.0315e-01, -1.3357e-01, -5.8250e-01],\n",
            "          [-1.1762e-01, -3.6862e-01,  3.3182e-01, -1.3866e-01,  5.2397e-01]],\n",
            "\n",
            "         [[ 3.3169e-02, -7.8605e-01, -1.2821e+00,  1.5778e-01, -1.7786e-01],\n",
            "          [ 2.8484e-01, -7.4448e-01,  3.9655e-01,  3.2967e-01, -2.0061e-01],\n",
            "          [-6.4076e-01, -2.1304e+00,  8.9580e-01,  3.9465e-01,  1.3574e-01],\n",
            "          [-3.1314e-01, -7.2049e-01,  4.9991e-01,  2.2034e-01,  1.3491e-01],\n",
            "          [-6.4982e-02, -4.1934e-01,  1.4813e-01,  1.1845e-01, -9.9940e-02]],\n",
            "\n",
            "         [[-1.9282e+00,  2.0240e-01,  5.7857e-01,  7.6572e-02, -7.3102e-01],\n",
            "          [-1.7521e+00,  4.1639e-01,  1.1786e-01, -1.8921e-01, -1.0605e+00],\n",
            "          [-3.9505e-01,  2.8607e-01,  5.2322e-02, -6.7047e-01, -1.4598e+00],\n",
            "          [-7.1158e-02,  5.3029e-01,  1.8659e-01, -2.1171e+00, -4.2254e-01],\n",
            "          [ 2.5558e-01,  3.9995e-01,  3.3518e-01, -5.6004e-01,  1.5144e-02]],\n",
            "\n",
            "         [[-4.7123e-01, -3.4038e-01,  4.1633e-01,  1.6363e-01, -1.7861e-01],\n",
            "          [ 1.1634e-01, -1.4594e-01, -2.8525e-02,  1.4104e-01, -4.3832e-01],\n",
            "          [ 4.3392e-01,  5.0512e-02, -5.7331e-01, -5.3742e-01, -3.8936e-01],\n",
            "          [ 3.3880e-01, -7.8638e-01, -1.3955e+00, -2.6407e-01, -2.3621e-01],\n",
            "          [-2.7368e-01, -1.4778e+00, -1.1833e+00,  6.5136e-02,  4.1986e-01]],\n",
            "\n",
            "         [[-1.3651e-01,  2.8307e-01,  6.1320e-01,  2.8682e-01, -8.0439e-01],\n",
            "          [-4.9718e-01,  2.0454e-01,  1.9599e-01, -8.4458e-01, -2.5263e-01],\n",
            "          [-1.3628e+00, -8.2653e-01, -5.9176e-01, -5.1392e-01, -6.2214e-01],\n",
            "          [-6.0532e-01, -7.4314e-01, -9.5029e-01, -9.8086e-01,  4.7351e-01],\n",
            "          [-1.2648e+00, -6.6435e-01, -3.4820e-01, -1.8036e-01, -2.4930e-01]],\n",
            "\n",
            "         [[-6.0692e-01, -7.7691e-01,  2.7228e-01,  2.1154e-01, -2.9895e-02],\n",
            "          [-1.1134e+00, -1.3650e+00, -1.9704e-01,  4.7215e-02, -5.5564e-01],\n",
            "          [-8.6621e-01, -3.8861e-01,  4.8931e-01,  1.8483e-01, -1.0956e+00],\n",
            "          [-4.2918e-01,  4.8850e-01,  2.6914e-01, -5.5953e-01, -4.5375e-01],\n",
            "          [ 2.6946e-02,  3.5309e-01, -7.0792e-01,  2.9610e-02,  5.7636e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 9.4993e-02, -1.9250e-01, -2.5832e-01,  1.5935e-01,  6.2593e-02],\n",
            "          [ 1.5704e-01,  8.6614e-02, -4.3384e-01, -1.4959e-01,  7.6239e-02],\n",
            "          [-6.0718e-02,  2.9169e-01,  2.4465e-01,  2.1640e-01,  5.2623e-01],\n",
            "          [ 1.5923e-01, -4.1353e-01,  1.9195e-01, -3.5454e-01,  3.6946e-01],\n",
            "          [-1.2850e-01, -1.3458e-01, -1.0745e+00, -8.2697e-01, -1.8109e-01]],\n",
            "\n",
            "         [[-6.3750e-01, -1.3665e-01,  1.8572e-01,  1.2988e-01,  2.7092e-01],\n",
            "          [-1.9920e+00, -1.1698e+00, -3.0331e-01, -4.7772e-01, -1.0399e-01],\n",
            "          [ 3.4768e-01, -1.3515e+00, -1.6002e+00, -8.4675e-01,  1.6233e-02],\n",
            "          [ 3.3287e-01,  1.5037e-01,  5.3761e-01,  3.9365e-01,  3.2010e-01],\n",
            "          [ 6.5693e-02,  3.6527e-01,  3.3434e-01, -2.2434e-01,  8.6952e-01]],\n",
            "\n",
            "         [[-8.9746e-02,  6.0441e-02,  4.8969e-01,  1.1101e-01, -1.4023e-01],\n",
            "          [ 1.1931e-01,  5.9618e-01,  1.1321e-01, -7.5346e-01, -4.8334e-01],\n",
            "          [-9.4144e-03,  2.8381e-02, -4.7882e-01, -1.0168e+00,  4.6541e-02],\n",
            "          [-8.4414e-01, -8.0749e-01, -1.9564e+00, -6.9421e-01, -9.7621e-01],\n",
            "          [-1.3127e+00, -1.2507e+00, -2.6341e-01,  7.8432e-01, -2.1184e-01]],\n",
            "\n",
            "         [[-8.6132e-01, -1.8899e-01, -1.5297e-02, -2.9516e-01,  9.0957e-02],\n",
            "          [ 1.7060e-02, -4.7818e-01, -6.4260e-01, -9.0523e-02,  7.4719e-01],\n",
            "          [ 1.6331e-01,  2.4412e-01,  1.7777e-01, -1.2239e-01,  6.7157e-01],\n",
            "          [-3.7538e-01,  5.6783e-01,  1.1384e+00, -2.4041e-01, -1.3381e-01],\n",
            "          [-1.0233e+00,  1.1110e-02,  5.3736e-01, -6.5547e-01, -8.3061e-01]],\n",
            "\n",
            "         [[-1.2314e-01, -1.4978e+00, -9.6802e-01,  2.5181e-01, -2.2140e-01],\n",
            "          [ 7.2382e-01, -2.7205e-01, -6.5228e-01, -4.5762e-01, -6.2108e-01],\n",
            "          [ 3.4323e-01,  6.8144e-01,  1.7665e-01, -2.1404e-01, -2.1111e-01],\n",
            "          [ 2.5451e-01,  2.0515e-01,  6.3789e-01,  3.4610e-01, -3.7548e-02],\n",
            "          [-7.8052e-01, -2.8024e-01, -9.9256e-01, -9.1416e-01, -6.0320e-01]],\n",
            "\n",
            "         [[ 3.8480e-02,  1.9682e-01,  4.3526e-01,  4.6582e-01,  2.6867e-01],\n",
            "          [ 2.0337e-01, -1.4343e-01,  2.6292e-01,  3.9709e-01,  4.4196e-01],\n",
            "          [-3.1050e-01, -8.4777e-01, -4.6410e-01, -3.5536e-02,  5.8281e-01],\n",
            "          [-7.7749e-01, -2.3261e-01, -8.2932e-01, -9.6928e-01, -8.7092e-01],\n",
            "          [ 9.3106e-02, -7.9129e-02, -5.8498e-01,  5.8778e-02,  1.6726e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 4.3033e-01,  3.4276e-01,  2.6612e-01,  4.4351e-01,  8.5990e-01],\n",
            "          [ 1.6013e-01,  6.3754e-01, -2.3427e-01,  8.2872e-02,  4.8397e-01],\n",
            "          [-1.1550e+00, -8.3642e-01, -8.0298e-01, -1.0031e+00, -9.9399e-01],\n",
            "          [-1.5915e-01,  1.7368e-01, -3.8560e-01, -8.0209e-01, -6.4144e-01],\n",
            "          [ 1.5884e-01, -3.0625e-01, -2.6821e-01, -6.5637e-01, -1.2696e-01]],\n",
            "\n",
            "         [[-9.1968e-01, -2.7718e-01,  2.0833e-01, -6.4261e-01,  7.0366e-02],\n",
            "          [ 1.7758e-01,  2.3979e-01, -1.8502e-01,  6.3342e-02,  3.9733e-01],\n",
            "          [ 5.7078e-02,  7.1099e-02,  8.7102e-02, -1.2012e-01,  5.9146e-01],\n",
            "          [-8.8482e-01, -7.9540e-01, -1.1518e+00, -1.5516e+00, -1.3856e-01],\n",
            "          [-1.2394e+00, -2.5989e-01, -9.5138e-01, -5.0602e-01, -1.0717e+00]],\n",
            "\n",
            "         [[-1.3934e-01, -3.0047e-01,  1.3564e-01,  3.2984e-01,  8.6670e-02],\n",
            "          [-1.7633e+00, -2.5226e-01, -9.9114e-01, -3.9232e-01,  8.4901e-02],\n",
            "          [-6.9723e-01, -8.5039e-01, -1.3301e+00, -9.0926e-01, -2.1673e+00],\n",
            "          [-4.1206e-01, -7.4752e-01, -1.1059e+00, -7.6153e-01, -1.9169e+00],\n",
            "          [-1.4207e-01, -5.0340e-01, -7.4020e-01, -5.3632e-01, -4.8492e-02]],\n",
            "\n",
            "         [[ 5.5353e-01,  4.9066e-01,  2.8445e-01, -1.9733e-01,  2.8577e-01],\n",
            "          [-1.0580e+00, -5.6577e-01, -1.4127e+00, -8.8738e-03,  4.3480e-01],\n",
            "          [ 1.1627e-01,  5.2067e-01,  2.2243e-01, -2.9990e-01,  4.3837e-01],\n",
            "          [ 1.3382e-01, -3.5368e-01, -1.4590e+00, -1.2954e+00,  5.6908e-01],\n",
            "          [-4.3674e-02, -5.1265e-01, -4.8016e-01,  1.5149e-01,  2.2779e-01]],\n",
            "\n",
            "         [[-8.1912e-03, -1.8876e-01,  3.3061e-01,  1.7384e-01,  5.2298e-01],\n",
            "          [ 3.2672e-01,  4.8261e-01,  5.7962e-01,  4.6360e-01,  7.6193e-01],\n",
            "          [-3.8110e-01, -6.2831e-01, -5.5364e-01, -6.4478e-01, -1.8296e-01],\n",
            "          [-1.4899e+00, -6.8600e-01, -9.2026e-01, -8.6685e-01, -7.5809e-01],\n",
            "          [-5.4110e-01, -4.7735e-01, -8.3073e-01, -7.4323e-01, -1.6151e+00]],\n",
            "\n",
            "         [[ 6.9498e-01, -3.7158e-01, -8.4897e-02,  1.4294e-01,  4.8056e-01],\n",
            "          [ 1.8767e-01, -3.0292e-01, -4.7701e-01, -2.2604e-01, -4.2731e-01],\n",
            "          [-1.1594e+00, -1.0047e+00, -6.9584e-01, -5.1545e-01, -1.0235e+00],\n",
            "          [-7.5260e-01,  6.0448e-02, -7.2656e-01, -6.0151e-01, -9.9857e-01],\n",
            "          [ 3.9064e-01,  1.4748e-01, -3.2537e-01, -7.4291e-01, -3.5792e-01]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1.6571e-01,  4.3960e-01, -2.1077e-01, -1.2691e+00, -1.3945e+00],\n",
            "          [-5.2285e-01, -6.1585e-01, -4.7012e-01, -8.6888e-01, -8.5045e-01],\n",
            "          [-3.3042e-01, -1.2437e+00, -8.8805e-01, -5.3056e-01,  2.9548e-01],\n",
            "          [-2.7167e-01, -1.0658e+00, -3.5374e-01, -4.4282e-01, -4.1068e-01],\n",
            "          [-2.2901e-01, -7.0802e-01, -1.0147e+00, -3.3478e-01, -5.4774e-01]],\n",
            "\n",
            "         [[ 4.7784e-01,  1.8794e-01,  8.5187e-01, -2.9537e-01, -1.3702e+00],\n",
            "          [ 5.9977e-01,  3.6731e-02,  2.4784e-01, -1.0366e+00, -9.7162e-01],\n",
            "          [ 7.1867e-02, -4.7950e-01, -5.4198e-01, -3.7233e-01, -7.8268e-02],\n",
            "          [-5.1644e-02, -2.7368e-01, -7.6922e-01,  3.6314e-01,  7.7848e-02],\n",
            "          [ 2.3321e-01, -3.8746e-01, -1.2548e+00, -5.6232e-02, -9.0931e-01]],\n",
            "\n",
            "         [[ 4.5156e-01, -8.0847e-01,  6.4472e-02, -8.6116e-01, -1.9635e-01],\n",
            "          [-7.6271e-01, -5.7053e-01,  4.1270e-02, -4.7220e-01, -9.8095e-01],\n",
            "          [-8.8585e-01, -3.1144e-01, -4.9601e-01, -4.7591e-01, -5.4544e-01],\n",
            "          [-7.6469e-01, -1.2026e+00, -5.0029e-01, -8.8639e-01, -4.3296e-01],\n",
            "          [-1.0401e+00, -9.9011e-01, -4.1567e-01, -5.0220e-02,  5.5804e-01]],\n",
            "\n",
            "         [[ 7.3410e-01,  3.5068e-01,  5.0086e-01,  2.4840e-01,  1.9756e-01],\n",
            "          [ 9.7563e-02, -2.7875e-01, -8.3715e-01, -1.6681e-01, -1.4259e-01],\n",
            "          [-1.0866e-01, -1.5920e-01, -1.4175e-01,  1.0814e-01,  4.5415e-01],\n",
            "          [-1.1177e+00, -6.4127e-01, -9.2022e-01, -1.0716e+00, -1.1394e+00],\n",
            "          [-2.4429e+00, -7.6479e-01, -2.0867e-01,  1.0498e-01,  1.0694e+00]],\n",
            "\n",
            "         [[ 9.2251e-01,  3.5758e-01, -6.7893e-01, -1.7584e+00, -9.2561e-01],\n",
            "          [ 2.1715e-01,  1.5888e-01, -7.2785e-01, -1.3960e+00, -7.5264e-02],\n",
            "          [-4.1579e-01, -8.2499e-01, -7.6197e-01, -1.3925e+00, -5.2519e-01],\n",
            "          [-7.3817e-01, -9.1798e-01, -6.6217e-01, -8.9414e-01, -4.2435e-01],\n",
            "          [-1.8031e+00, -1.3610e+00, -4.8482e-01, -3.2628e-01, -6.6722e-02]],\n",
            "\n",
            "         [[ 5.8525e-01, -4.5123e-01, -3.2929e-01, -2.5192e-01, -6.5898e-01],\n",
            "          [-5.2548e-01, -6.2704e-01,  3.3039e-04, -1.1155e+00, -7.5812e-01],\n",
            "          [-1.0919e+00, -1.1802e+00, -3.9917e-01, -1.4814e-01,  2.3895e-01],\n",
            "          [-1.6332e-01, -7.8166e-01,  7.1963e-02,  2.1660e-01,  2.9106e-01],\n",
            "          [ 3.4783e-01, -1.8459e-01, -1.2314e+00, -1.0197e+00, -8.2686e-01]]],\n",
            "\n",
            "\n",
            "        [[[-5.9071e-01,  3.3200e-01, -4.0366e-01, -1.0708e-01,  4.7536e-02],\n",
            "          [ 1.3772e-01,  2.0737e-01,  3.2719e-01, -1.0074e-01, -1.2162e-01],\n",
            "          [ 5.9456e-01,  6.0975e-02,  1.6575e-01, -9.8380e-02, -7.7903e-01],\n",
            "          [ 1.4467e-01,  4.1810e-01, -8.3383e-01, -1.0439e+00, -9.7619e-01],\n",
            "          [ 2.0123e-01,  6.9169e-02, -4.8208e-01, -1.3971e-01, -3.8624e-01]],\n",
            "\n",
            "         [[ 9.4823e-02, -1.4586e-01, -6.6931e-02,  7.4484e-02,  1.6524e-01],\n",
            "          [-1.5317e-01, -1.8071e-01,  2.7111e-01,  4.9194e-01,  4.1620e-01],\n",
            "          [-3.9987e-01,  1.6704e-01,  5.5199e-01,  3.9592e-01,  5.3904e-01],\n",
            "          [-4.2247e-01,  2.0207e-01,  1.5008e-01, -9.4318e-01, -1.1535e+00],\n",
            "          [-1.5605e+00, -7.5484e-01, -9.4215e-01, -1.2848e+00, -1.4316e+00]],\n",
            "\n",
            "         [[ 5.5632e-02, -6.9440e-02, -1.6120e-01,  3.4874e-01, -1.2457e+00],\n",
            "          [-2.4670e-01,  7.5157e-01,  1.8866e-01, -7.7765e-01, -1.1315e+00],\n",
            "          [-5.9444e-01, -8.5526e-02, -6.6999e-01, -1.0288e+00,  1.1649e-01],\n",
            "          [-1.3238e+00, -9.7470e-01, -1.3119e+00, -1.1547e+00, -4.7127e-01],\n",
            "          [-5.9456e-01, -3.1605e-01, -9.1362e-01, -5.2283e-01, -4.7664e-01]],\n",
            "\n",
            "         [[ 1.3480e-01,  2.0663e-01,  1.2057e-01, -1.1597e-02,  3.1769e-01],\n",
            "          [-5.2637e-01,  2.0339e-01,  2.6420e-01, -7.3995e-01, -1.2290e+00],\n",
            "          [-3.8321e-01, -7.7803e-01, -6.2343e-01, -1.1112e+00, -1.1685e+00],\n",
            "          [ 9.5131e-02,  3.1893e-01,  4.8771e-01,  1.0624e-01, -4.5251e-01],\n",
            "          [ 4.9387e-01,  5.2903e-01, -1.0984e-01, -1.5045e-01, -3.7869e-01]],\n",
            "\n",
            "         [[-9.2966e-01, -2.0975e-01, -1.9402e-01, -9.0046e-01, -4.6594e-01],\n",
            "          [-4.3426e-01, -2.8744e-03,  3.2045e-01,  1.8180e-01,  1.3423e-01],\n",
            "          [ 5.3463e-01,  1.0414e+00,  7.5004e-01, -1.4330e-01, -1.1366e+00],\n",
            "          [ 4.4539e-01, -8.0490e-02, -1.4641e+00, -1.3826e+00, -1.4171e+00],\n",
            "          [-3.4637e-01, -7.3696e-01, -1.1237e+00, -3.7664e-01, -8.7919e-01]],\n",
            "\n",
            "         [[ 6.0305e-01, -3.5160e-01, -7.1459e-02,  2.6925e-01, -3.2504e-01],\n",
            "          [-6.5780e-01,  3.1661e-01,  6.8145e-01,  2.1859e-01, -6.5837e-01],\n",
            "          [-6.7572e-01,  1.7506e-01,  6.1645e-02, -5.0902e-01, -5.2824e-01],\n",
            "          [-6.2382e-01, -9.8014e-01, -5.4132e-01, -1.1627e+00, -1.2130e+00],\n",
            "          [-1.5570e-01, -5.1739e-01, -8.7591e-01, -6.2824e-01, -3.6396e-01]]],\n",
            "\n",
            "\n",
            "        [[[-1.1817e-01, -4.5374e-01,  3.6171e-01,  4.0136e-01, -7.7421e-01],\n",
            "          [-8.0281e-01, -1.0062e+00,  1.6194e-01,  2.0377e-01, -1.0487e+00],\n",
            "          [-7.8386e-01, -2.3605e+00,  1.8478e-02,  2.8797e-01, -1.6574e-01],\n",
            "          [-1.5671e+00, -1.8349e+00, -9.8271e-01, -8.4901e-01, -3.1479e-01],\n",
            "          [-1.0420e+00, -1.2468e+00, -4.6100e-02,  7.6188e-01,  7.2403e-02]],\n",
            "\n",
            "         [[-9.7303e-01, -2.0160e+00, -1.3955e+00, -3.7125e-01, -8.3057e-03],\n",
            "          [-5.4134e-01, -5.0417e-01, -1.4094e+00, -6.9668e-03,  2.3046e-01],\n",
            "          [ 1.2084e-01, -5.7332e-01, -1.5077e+00,  1.0490e-01,  3.4619e-01],\n",
            "          [-3.5609e-01, -1.6692e+00, -5.3280e-02, -2.4227e-02,  2.1601e-01],\n",
            "          [-2.7403e-02, -1.0906e+00, -5.4834e-01,  3.9605e-01, -2.7807e-01]],\n",
            "\n",
            "         [[ 4.1250e-01,  2.2321e-01, -4.8997e-01, -5.0031e-01, -1.0976e+00],\n",
            "          [-2.0460e-01, -1.1397e+00, -1.5183e+00, -9.5921e-01, -2.0160e+00],\n",
            "          [-4.9159e-01, -5.5844e-01, -1.3760e-01,  1.5856e-01, -2.3484e+00],\n",
            "          [ 1.1524e-01, -7.8255e-02, -3.6811e-02,  4.7844e-01, -1.1391e+00],\n",
            "          [ 2.6212e-01, -2.9785e-01,  7.6518e-02, -1.5143e-01, -3.6566e-01]],\n",
            "\n",
            "         [[-4.9158e-01,  2.6912e-01,  3.3520e-01, -2.5875e-01, -9.2739e-01],\n",
            "          [-3.9636e-01,  6.0906e-02, -3.7366e-01, -1.2547e-02, -5.4037e-01],\n",
            "          [-3.2064e-01, -3.0045e-01,  2.1599e-01, -6.1447e-01, -1.2397e-01],\n",
            "          [-4.5694e-01, -6.0199e-01, -5.6373e-01, -9.2601e-01, -5.1790e-01],\n",
            "          [-1.7665e-01, -8.3625e-01, -2.3691e-01, -4.4007e-01, -4.7689e-01]],\n",
            "\n",
            "         [[-1.8643e-01,  2.8497e-01,  7.5870e-01,  2.5382e-02, -1.6516e+00],\n",
            "          [ 8.1734e-03,  2.4238e-01,  1.5376e-01, -9.6183e-01, -1.1107e+00],\n",
            "          [-6.9159e-02, -5.1301e-01, -1.0557e-01, -2.9813e-01, -1.1223e+00],\n",
            "          [-8.8897e-01, -1.6387e-02,  1.1008e-01, -2.9264e-01, -8.8788e-02],\n",
            "          [-7.8432e-01, -3.6359e-01, -1.7303e-02,  6.2207e-02, -3.3195e-01]],\n",
            "\n",
            "         [[-5.1584e-01,  2.8016e-01,  4.3947e-01, -5.3113e-02, -1.4070e-01],\n",
            "          [ 2.3429e-01,  4.7651e-01, -1.3445e+00, -8.5329e-01,  4.6237e-02],\n",
            "          [-3.0961e-01, -9.9974e-02, -1.3331e-01,  8.6865e-02, -4.2432e-01],\n",
            "          [ 4.0818e-02, -1.1933e-02, -3.6688e-01,  3.3452e-02, -3.2371e-02],\n",
            "          [-2.4733e-01, -3.8122e-01, -7.0713e-01, -5.3535e-01, -1.8517e-01]]]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "conv2.bias\n",
            "Parameter containing:\n",
            "tensor([-0.1534, -0.2397,  0.0012, -0.4733, -0.1539, -0.7999, -0.3259, -0.2238,\n",
            "        -0.4183, -0.4043,  0.0188, -0.4372, -0.1633,  0.7453, -0.2758, -0.0915],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "fc1.weight\n",
            "Parameter containing:\n",
            "tensor([[-0.0254, -0.0970, -0.1038,  ...,  0.0089, -0.0148, -0.0637],\n",
            "        [-0.3422, -0.2865, -1.1367,  ...,  0.5930,  0.2031, -0.3008],\n",
            "        [-0.0207, -0.0885, -0.0908,  ..., -0.0300, -0.0257, -0.0399],\n",
            "        ...,\n",
            "        [-0.2457, -0.7616, -0.0860,  ..., -1.1921, -0.1226, -0.8333],\n",
            "        [ 0.1872,  0.1328,  0.6814,  ..., -1.2316,  0.0404,  0.0844],\n",
            "        [-0.8365, -0.7401, -0.9220,  ..., -0.2605, -0.3604, -0.8173]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "fc1.bias\n",
            "Parameter containing:\n",
            "tensor([-0.1054, -0.3491, -0.1026, -0.3249, -0.2515, -0.2464, -0.2875, -0.4670,\n",
            "        -0.0943, -0.3236, -0.4717, -0.6985,  0.0306,  0.0138, -0.1625, -0.0754,\n",
            "        -0.5959, -0.7218,  0.2977, -0.4735, -0.0423, -0.0231, -0.3133, -0.1103,\n",
            "        -0.1033,  0.3601, -0.2859, -0.0586, -0.1007, -0.4330, -0.5062, -0.0460,\n",
            "        -0.7744, -0.1616, -0.3035, -0.0922, -0.8161, -0.0680, -0.1265,  0.2874,\n",
            "        -0.4889,  0.0153, -0.1128, -0.5344, -0.2156, -0.0513, -0.1197, -0.1121,\n",
            "        -0.6585, -0.1858,  0.0034, -0.0043, -0.5976, -0.2578,  0.8449,  0.2197,\n",
            "        -0.0302, -0.2037, -0.0790,  0.1032,  0.6256, -0.0380, -0.0178, -0.1030,\n",
            "        -0.3968,  0.0870, -0.4467, -1.1891, -0.3694, -0.0672,  0.0192, -0.1024,\n",
            "        -0.2210, -0.5217, -0.2258, -0.3438, -0.0815, -0.1630, -0.0106,  0.0170,\n",
            "        -0.5420, -0.0740, -0.0222, -0.0772, -0.1456,  0.2818, -0.5593, -0.1293,\n",
            "        -0.3264, -0.0989, -1.3253, -0.8759, -0.3500, -0.5491, -0.1159, -0.0917,\n",
            "        -0.0233, -0.2362, -0.4016, -0.3344, -0.0080,  0.0470, -0.4096, -0.4640,\n",
            "        -0.6862, -0.0243, -0.5664, -0.6208, -0.0784,  0.1788,  0.4371, -0.1072,\n",
            "         0.4788,  0.0388, -0.0841, -0.5341, -0.0891, -0.4399, -0.6531, -0.5295],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "fc2.weight\n",
            "Parameter containing:\n",
            "tensor([[ 0.0727, -0.6423, -0.0704,  ...,  0.0178, -0.2922, -0.8178],\n",
            "        [ 0.0105, -0.5508,  0.0194,  ..., -0.5857, -0.3430, -0.4576],\n",
            "        [ 0.0457, -0.8621, -0.0394,  ..., -0.0558, -0.5278, -0.5511],\n",
            "        ...,\n",
            "        [ 0.0835, -0.3410, -0.0325,  ..., -0.4933,  0.2078,  0.0280],\n",
            "        [-0.0756, -0.7164,  0.0057,  ...,  0.5291, -0.4202, -0.2957],\n",
            "        [ 0.0766, -0.6101, -0.0948,  ..., -0.4799, -1.1854, -0.2722]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "fc2.bias\n",
            "Parameter containing:\n",
            "tensor([-1.2547, -0.5346, -1.2259, -0.4103,  0.0095,  0.0733,  0.4242, -0.0391,\n",
            "         0.6422, -0.2244, -1.1534, -0.6695, -0.3069,  0.5618, -0.1766, -1.2993,\n",
            "        -0.8581,  0.4624,  0.0372, -0.2573,  0.5694, -0.0936, -1.1343,  0.4329,\n",
            "        -0.1163, -0.5936,  0.2407, -0.3312, -0.8314,  0.2328, -0.6267, -0.0630,\n",
            "        -0.2236, -0.6953, -0.7796,  0.4216,  0.4457, -0.2252, -0.1019, -0.9461,\n",
            "        -0.1494,  0.1272, -0.0596,  0.3050, -0.7336, -1.5037, -0.3482, -0.5246,\n",
            "        -1.1766, -0.3661, -1.0718, -0.6175, -0.8544, -0.4444, -0.8152, -0.8990,\n",
            "         0.6607, -1.0276, -0.5675, -0.3674, -0.8082, -0.2234, -0.7406, -0.8497,\n",
            "        -0.6405,  0.0450,  0.4325, -0.3230, -0.6137, -0.3090, -0.5132, -0.7516,\n",
            "        -0.3587, -0.4870, -0.4234, -0.3384, -0.5853, -0.8773, -1.2145, -0.1697,\n",
            "        -1.1732,  0.8365, -1.1260, -1.1205], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "fc3.weight\n",
            "Parameter containing:\n",
            "tensor([[-3.2866e-01, -1.6324e-01, -6.2560e-01,  2.0737e-01,  2.1103e-02,\n",
            "         -1.5180e-01, -1.7011e-01,  2.2610e-01, -5.5265e-01, -1.7998e-04,\n",
            "         -3.5033e-02,  4.9310e-02, -5.0065e-01,  3.6674e-01, -1.4452e-01,\n",
            "          3.3537e-01, -1.9632e-01, -2.0292e-01, -2.1160e-01, -5.9922e-02,\n",
            "          2.8072e-02, -7.9639e-02, -2.5672e-01, -2.5742e-01, -3.9278e-01,\n",
            "          4.9996e-02, -1.8463e-02,  5.3957e-02, -9.1008e-02, -1.8635e-01,\n",
            "          9.9281e-02,  3.9508e-01, -5.9264e-01, -3.0709e-01, -5.3661e-03,\n",
            "         -2.3725e-01,  1.1060e-01, -8.8924e-02, -2.8067e-02, -5.1184e-01,\n",
            "         -1.8661e-01, -1.4541e-02,  7.9477e-03, -5.8453e-01, -2.3834e-02,\n",
            "         -1.3629e-01,  1.7552e-01,  2.4416e-01, -3.6024e-01,  2.2098e-01,\n",
            "          3.1393e-01, -1.6941e-01, -1.0405e-01, -1.2265e-01, -3.0733e-01,\n",
            "         -5.0734e-02, -4.4929e-02, -8.9088e-01, -2.3573e-02,  2.0082e-01,\n",
            "         -3.2662e-01,  2.8489e-02, -1.4263e+00, -2.9857e-01, -8.7874e-02,\n",
            "          1.5895e-03, -2.0623e-01,  1.3607e-02,  3.1272e-01, -1.1973e-02,\n",
            "         -1.5795e-01, -1.5530e-01,  2.7069e-01,  1.8752e-01, -3.4256e-02,\n",
            "          1.6897e-01,  1.2748e-02, -1.9003e-01, -2.8149e-01, -2.5551e-01,\n",
            "         -6.1319e-01, -2.5331e-01, -9.3168e-02,  9.6258e-02],\n",
            "        [-5.9573e-01, -4.8056e-01, -4.8949e-01,  1.2373e-02, -3.3900e-01,\n",
            "         -1.3446e-01,  3.2430e-01, -9.3727e-01,  2.1656e-01, -2.1791e+00,\n",
            "         -1.3794e-01, -9.7089e-02, -3.5202e-02, -4.4208e-01, -1.3135e-01,\n",
            "          2.8966e-02, -1.1907e-01, -2.0379e-01, -2.5222e-01,  1.2316e-02,\n",
            "          1.8716e-01,  7.1105e-02, -1.8912e-01, -5.4538e-01, -4.0103e-01,\n",
            "         -4.3643e-01, -1.2738e-01, -3.1544e-01, -8.8314e-02, -3.0622e-02,\n",
            "         -4.2898e-02, -7.4670e-01,  1.5875e-01, -3.3550e-01,  4.6842e-02,\n",
            "         -2.1456e-01, -2.0492e-01,  1.7354e-01, -1.1400e-01, -5.0184e-01,\n",
            "         -1.2972e-01, -2.9756e-01, -4.3709e-02, -3.4222e-01, -1.3908e-01,\n",
            "          1.1297e-01,  1.1252e-01, -3.7810e-01, -3.0455e-01, -1.2897e-01,\n",
            "          4.7160e-02, -1.3167e-01,  1.2090e-03,  1.4573e-01, -3.2855e-02,\n",
            "         -4.2309e-01,  4.3570e-02, -7.4186e-01, -9.5000e-02, -9.3706e-02,\n",
            "         -4.9506e-01,  2.8667e-02, -3.3221e-01, -1.3354e-01, -2.8295e-01,\n",
            "         -4.4842e-01,  1.7764e-01, -5.4956e-02, -5.4331e-01,  1.6069e-02,\n",
            "         -9.3145e-02, -6.9225e-02, -1.6024e-01, -1.9714e-01, -1.0727e-01,\n",
            "          2.5881e-02,  1.5967e-02,  4.5065e-02,  1.7062e-01, -1.0885e-01,\n",
            "         -3.9264e-01, -1.2942e-01, -2.8833e-01, -4.2711e-01],\n",
            "        [-1.3610e+00,  5.9383e-02, -1.3695e-01,  6.3495e-02, -5.9470e-02,\n",
            "          1.8328e-01,  1.2438e-01, -1.5319e-01, -2.4167e-01, -1.1528e+00,\n",
            "          6.1247e-02,  7.5174e-02, -2.5209e-01,  2.4260e-02, -2.6688e-02,\n",
            "         -1.1085e-01, -7.7894e-02,  9.6684e-02, -1.4312e-01,  6.8180e-03,\n",
            "         -3.7260e-01,  4.3252e-01, -2.7834e-02, -4.4769e-01, -5.7350e-01,\n",
            "          1.7636e-01,  4.6213e-02,  1.3707e-01, -1.6018e-01, -3.2863e-02,\n",
            "         -5.4531e-01, -1.3162e-03, -2.2313e-01, -1.4658e-02, -3.4266e-01,\n",
            "         -1.6791e-01,  1.5677e-01, -9.6467e-03,  4.0593e-01, -5.4336e-02,\n",
            "          2.5092e-01,  2.6743e-01,  5.6794e-02, -2.9485e-01,  6.0066e-01,\n",
            "         -3.2830e-01, -1.6150e-01, -1.0550e-01, -9.4611e-02, -6.8926e-02,\n",
            "         -7.3988e-01, -3.7586e-01, -1.4085e-01,  3.2819e-02,  9.6896e-02,\n",
            "         -2.7095e-01, -2.1710e-01, -7.2064e-01,  2.1557e-01, -2.2819e-01,\n",
            "         -3.7641e-01,  4.5634e-02, -8.3641e-01, -5.0886e-01, -7.9875e-01,\n",
            "         -4.5799e-02,  2.3823e-01,  2.1764e-01,  1.9887e-01, -5.9274e-02,\n",
            "          6.9686e-02,  1.0035e-01, -9.0295e-01, -3.7927e-01,  1.3303e-01,\n",
            "          2.7135e-02,  4.8113e-02, -4.6535e-01, -2.9319e-01, -6.6545e-02,\n",
            "         -3.2101e-01, -2.8070e-01, -3.5421e-01,  5.6509e-02],\n",
            "        [-4.0483e-01, -3.0376e-02, -3.5637e-01,  3.8315e-02,  1.6740e-01,\n",
            "         -1.0869e-01, -2.3691e-01, -1.5048e-01,  4.1833e-01, -5.1132e-01,\n",
            "         -4.0750e-01, -2.2676e-01, -5.6935e-01,  3.2228e-02,  9.0389e-02,\n",
            "         -2.1505e-01, -2.4933e-01,  2.3981e-01, -2.3344e-01,  1.0865e-01,\n",
            "         -5.1178e-01, -2.1912e-01, -4.8986e-01, -3.0112e-01, -4.6759e-02,\n",
            "         -7.1550e-02,  1.6796e-01,  4.1183e-02, -1.1410e-01,  3.1769e-01,\n",
            "         -4.1663e-01, -4.6481e-02,  2.4135e-01,  5.8054e-02, -1.0871e-01,\n",
            "          6.1691e-02,  6.8458e-02, -7.7759e-02,  8.6244e-02,  4.1394e-02,\n",
            "          2.0969e-01,  3.9646e-02,  1.3700e-01,  2.5140e-01, -1.0805e-01,\n",
            "         -5.2753e-01, -2.2976e-01, -3.2772e-01, -8.2049e-01,  3.9048e-02,\n",
            "         -9.2159e-01, -1.5453e-01,  6.9841e-02, -3.6178e-02, -4.5670e-02,\n",
            "         -2.1152e-01, -7.0990e-02, -2.2726e-01,  1.8278e-01, -4.1631e-01,\n",
            "         -8.5216e-01,  9.0311e-02, -2.4371e-01, -3.5355e-01, -7.2803e-01,\n",
            "          1.1958e-01, -2.5420e-02,  7.4732e-02,  1.6125e-01,  4.1934e-02,\n",
            "          1.5874e-02,  9.7893e-03, -1.0301e-01,  1.3467e-01,  2.5775e-01,\n",
            "          2.7846e-02, -1.1801e-01,  1.7313e-01,  1.9288e-02, -2.2739e-01,\n",
            "         -1.0166e-01, -2.4066e-01,  3.9706e-02, -3.5307e-01],\n",
            "        [-1.2807e+00, -5.4802e-02, -3.5211e-01, -1.2166e-01,  6.1310e-02,\n",
            "          2.4354e-01, -2.9855e-01, -2.6108e-01, -2.5651e-01, -4.6689e-01,\n",
            "         -8.8125e-01,  1.8940e-01, -8.7238e-01, -3.6035e-01, -1.6898e-01,\n",
            "          5.3739e-02, -3.7755e-01, -9.9028e-02,  2.3670e-01, -3.4505e-01,\n",
            "          9.5656e-02, -1.0611e-02, -1.3014e-02,  2.5802e-01, -1.8258e-01,\n",
            "         -1.7661e-01, -2.0036e-01,  1.2417e-01, -1.2560e-01, -5.5084e-01,\n",
            "          2.8603e-02, -1.7864e-01,  1.2319e-01, -1.9835e-01, -4.1467e-02,\n",
            "         -3.1474e-01,  2.5586e-02, -1.5838e-01, -8.7691e-02, -1.7854e-01,\n",
            "         -7.7746e-01,  1.3338e-01,  4.9267e-01,  7.9685e-03, -3.1107e-01,\n",
            "         -2.9556e-01,  1.7868e-02, -2.0315e-01, -2.4122e-01, -2.6995e-01,\n",
            "          3.6885e-01, -9.8271e-03,  1.0470e-01,  6.8925e-02, -1.7811e-01,\n",
            "          2.8963e-01,  7.5761e-02, -5.1350e-01,  1.6539e-01,  1.4599e-01,\n",
            "         -2.8834e-01, -7.8524e-03, -1.4915e-01, -1.5947e-01, -1.2475e+00,\n",
            "         -1.4288e-01,  9.4255e-02,  1.4908e-03, -2.3176e-02, -2.3466e-02,\n",
            "         -7.0736e-02, -1.4257e-01,  4.4332e-02, -7.9880e-02, -1.9620e-01,\n",
            "         -5.6470e-02, -6.5241e-02, -7.4819e-02, -1.1987e+00, -4.2071e-01,\n",
            "          8.0605e-02, -1.5822e-01, -1.6677e-01, -6.2134e-01],\n",
            "        [-2.6053e-01,  3.4132e-01, -7.5561e-02, -1.5226e-02,  6.1873e-02,\n",
            "         -1.1886e-01, -3.8064e-01, -1.5250e-01,  1.4783e-01, -1.4903e+00,\n",
            "         -3.4993e-01, -3.8058e-02, -2.1564e-01,  7.4174e-02,  4.4634e-02,\n",
            "         -2.1264e-01, -8.3151e-02, -8.0592e-02,  3.8593e-03, -2.6696e-01,\n",
            "         -1.8820e-01, -1.1666e-01, -3.3794e-01,  4.1525e-03,  2.1853e-01,\n",
            "          2.2649e-01, -3.1302e-01,  4.9068e-02,  4.5679e-02,  1.9794e-01,\n",
            "         -9.7077e-02,  1.6093e-01,  7.0912e-03, -7.5160e-02,  3.0883e-02,\n",
            "          3.2358e-01, -5.2563e-01,  3.4346e-02,  1.5506e-01, -6.1550e-02,\n",
            "         -2.1544e-01, -7.9798e-02,  7.8711e-02,  2.4651e-01, -1.3444e-01,\n",
            "         -1.9818e-01, -1.4792e-01,  3.9117e-01, -2.8738e-01,  7.9235e-02,\n",
            "         -1.6054e-01, -1.4004e-01, -2.5703e-01, -1.2387e-01, -2.6728e-02,\n",
            "         -3.2641e-02, -1.7142e-01, -2.3784e-01, -1.5677e-01, -2.2782e-01,\n",
            "         -2.8368e-01, -4.0300e-01, -4.9602e-01, -3.6496e-01, -6.1271e-01,\n",
            "         -9.5802e-02, -4.4843e-01,  1.7302e-01,  1.6255e-02,  1.5254e-02,\n",
            "          1.9690e-01, -1.2338e-01, -5.7335e-01,  5.3121e-02, -4.7416e-01,\n",
            "          2.7305e-02, -8.6094e-02,  2.7032e-01,  1.2996e-01, -5.1864e-01,\n",
            "         -4.1501e-02,  1.2567e-01,  3.0857e-02, -3.4837e-02],\n",
            "        [ 9.1247e-02,  1.7708e-01, -5.1280e-01, -3.8687e-01,  3.0174e-01,\n",
            "         -4.8640e-01, -1.4622e-01,  2.0906e-01, -2.7879e-01, -2.0450e+00,\n",
            "         -1.7719e+00,  4.8085e-02, -4.6655e-01, -1.0815e-02, -7.7027e-04,\n",
            "         -1.0268e-01,  5.6430e-02, -2.8483e-01, -6.0946e-02, -4.5137e-01,\n",
            "          1.4722e-01,  4.6845e-02, -6.2946e-01, -1.7984e-01,  2.1017e-01,\n",
            "          2.8123e-01, -9.0289e-01, -2.0070e-01, -5.4715e-01, -3.0041e-01,\n",
            "          1.3821e-01,  4.8585e-02, -1.1026e-01, -3.4643e-01,  3.5260e-01,\n",
            "         -8.8200e-02, -5.6672e-01,  2.6597e-02, -5.4572e-02, -7.6304e-01,\n",
            "         -2.9659e-01,  8.5312e-03, -8.6762e-02, -1.7889e-01, -3.8464e-02,\n",
            "         -3.5046e-01, -5.3683e-02, -2.0427e-01, -7.9397e-01, -1.3155e-01,\n",
            "         -1.4434e-01,  1.7456e-02, -1.4230e-01,  1.3988e-01,  7.8305e-02,\n",
            "          3.2742e-01, -3.8683e-01, -6.8514e-02, -1.6112e-01,  8.5119e-02,\n",
            "         -6.0392e-01, -3.6988e-01, -6.7630e-01, -3.6119e-01, -4.4129e-01,\n",
            "         -3.3547e-01, -2.0150e-01,  7.6981e-02, -2.1670e-01, -5.1435e-02,\n",
            "         -6.0437e-01, -1.6378e-01, -1.1154e+00,  5.7304e-02, -4.3927e-01,\n",
            "         -4.4675e-02,  2.7441e-01, -5.8908e-01,  9.6695e-03,  6.6747e-03,\n",
            "         -5.5758e-01,  1.9186e-01, -1.6092e-02, -9.9123e-01],\n",
            "        [-1.1259e+00, -4.9741e-02, -2.1480e-01, -1.1135e-01, -2.8667e-01,\n",
            "          1.0530e-01, -1.9780e-01, -6.6910e-01, -6.3079e-02, -9.4251e-01,\n",
            "         -1.5239e-02,  1.6539e-01, -9.8243e-01, -2.9814e-01,  2.5186e-01,\n",
            "         -3.6119e-01, -2.2508e-01, -5.2362e-01,  1.3549e-01,  7.9350e-02,\n",
            "         -7.8734e-02, -1.1129e-01, -2.4265e-01, -9.1027e-02, -4.3824e-01,\n",
            "         -2.1153e-01,  1.9691e-01,  6.3469e-02, -2.7997e-01, -1.5955e-01,\n",
            "         -2.0030e-01, -2.6660e-01, -2.7761e-03, -2.0657e-01, -2.6092e-01,\n",
            "         -3.4823e-01, -2.4070e-01, -2.2684e-01, -8.4320e-02, -2.4830e-01,\n",
            "         -4.1365e-02, -9.9906e-02, -2.0317e-01,  1.7735e-01, -1.3128e-01,\n",
            "         -1.2044e-01, -3.2859e-01,  6.2481e-02,  8.4741e-03,  1.8751e-01,\n",
            "          2.2498e-01, -1.1210e-01, -9.7087e-02, -8.6599e-02,  1.9200e-01,\n",
            "         -5.3350e-02,  2.7744e-01, -4.7076e-01, -3.5745e-03,  9.3613e-02,\n",
            "         -3.3454e-01,  9.5990e-03, -1.1060e+00, -8.5113e-02, -4.3954e-01,\n",
            "         -3.1728e-02,  2.7381e-01,  2.5962e-02, -5.6305e-02, -3.3135e-02,\n",
            "          1.6344e-01, -1.4253e-01, -2.8533e-01,  7.2522e-02, -9.9797e-02,\n",
            "          6.4119e-03, -5.3377e-01, -4.0725e-01, -3.0912e-01, -1.6638e-01,\n",
            "         -3.0723e-01, -8.1574e-02,  8.0939e-02, -6.0345e-01],\n",
            "        [-4.9502e-01,  5.8897e-02, -7.1828e-01,  5.2415e-02,  5.7225e-02,\n",
            "          6.9223e-02, -2.3786e-02, -2.7857e-01, -1.0048e-01, -1.9977e+00,\n",
            "         -3.7663e-01, -1.1938e-01, -2.1434e-01,  1.7733e-01,  7.1150e-03,\n",
            "          1.3034e-01, -7.4457e-02,  3.3375e-01, -2.0616e-01,  1.3858e-01,\n",
            "         -5.0654e-02, -2.9080e-01,  3.1055e-02, -4.4516e-02,  6.1124e-02,\n",
            "         -5.3966e-02, -1.9695e-01, -2.9997e-02, -8.2334e-01, -1.3394e-01,\n",
            "          1.3323e-01, -1.0135e-02, -4.0484e-01, -4.4335e-02, -1.1730e-01,\n",
            "          5.4381e-02,  3.1754e-01,  2.1078e-01, -1.8283e-01, -8.6596e-02,\n",
            "          2.4281e-01,  5.4315e-02,  1.1260e-01, -1.5108e-02, -1.3078e-01,\n",
            "          1.7407e-01,  1.4681e-01, -2.0973e-01, -5.5413e-02, -1.6953e-01,\n",
            "         -5.8099e-01,  7.9023e-02,  4.0676e-01, -2.9770e-02,  9.8105e-02,\n",
            "         -5.7756e-02, -3.5160e-01, -1.3306e-01,  1.5547e-01, -2.8257e-01,\n",
            "         -4.1450e-01,  1.5590e-02, -1.2937e+00, -4.4919e-01, -4.7500e-01,\n",
            "          1.1240e-01, -7.8168e-02, -1.6499e-01,  5.1305e-02, -1.1269e-01,\n",
            "          6.8147e-02, -1.4303e-01, -9.0935e-02,  1.0715e-01,  1.2900e-01,\n",
            "          5.1831e-02, -1.3982e-01, -1.5072e-01, -4.4103e-01,  3.4736e-02,\n",
            "         -2.0649e-01,  3.1735e-01, -1.4390e-01, -6.4827e-01],\n",
            "        [-1.1092e+00, -2.4312e-01, -8.3666e-01, -1.6942e-01,  2.5066e-01,\n",
            "          2.8461e-01, -1.9640e-01,  9.0286e-02, -1.9701e-01, -4.7627e-01,\n",
            "         -4.7904e-01,  9.6390e-02, -7.9294e-01, -2.0457e-01, -3.9836e-02,\n",
            "         -2.7272e-01, -6.7622e-02, -9.0328e-02,  4.3515e-02,  7.5248e-02,\n",
            "         -4.9417e-02, -1.5618e-03, -1.4573e-01,  2.4906e-01,  1.1613e-01,\n",
            "         -2.2982e-01, -2.2260e-01,  8.5640e-02, -3.6149e-01, -6.4349e-02,\n",
            "         -5.1680e-01, -9.1679e-02,  1.5027e-01, -2.6963e-01, -6.0615e-01,\n",
            "         -2.9325e-02,  7.3146e-02,  9.0320e-02, -2.9238e-01,  5.8645e-02,\n",
            "         -3.2733e-01, -1.9169e-01,  4.4278e-02,  2.2581e-02,  1.0081e-02,\n",
            "         -4.3797e-01, -1.8377e-01, -1.1849e-01, -1.7617e-01,  1.9503e-01,\n",
            "         -5.8068e-01, -2.5473e-02, -1.8120e-01, -1.6224e-01,  7.8717e-02,\n",
            "         -3.1291e-02,  1.9640e-01, -4.9032e-01, -1.9688e-01,  3.2082e-02,\n",
            "         -2.4664e-01,  5.9566e-02, -8.2624e-01,  2.7309e-02, -6.4508e-01,\n",
            "          2.6580e-01, -2.0405e-02, -7.1276e-02, -1.0758e-01, -1.0494e-01,\n",
            "         -6.6015e-02, -3.9874e-02, -2.1394e-01, -1.7471e-01,  1.1087e-01,\n",
            "         -4.4666e-02, -1.1147e+00, -1.3961e-01,  2.6304e-02, -1.5012e-01,\n",
            "          1.8154e-01,  1.2739e-02,  1.5302e-01, -5.0670e-01]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "fc3.bias\n",
            "Parameter containing:\n",
            "tensor([ 0.2780,  0.2636,  0.0286, -0.1082, -0.3353, -0.1207, -0.5127,  0.2415,\n",
            "         0.3964, -0.0675], device='cuda:0', requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "for name,param in model.named_parameters():\n",
        "    print(name)\n",
        "    print(param)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1/10, step 100/600, loss=0.2338\n",
            "epoch 1/10, step 200/600, loss=0.1110\n",
            "epoch 1/10, step 300/600, loss=0.0607\n",
            "epoch 1/10, step 400/600, loss=0.0770\n",
            "epoch 1/10, step 500/600, loss=0.0279\n",
            "epoch 1/10, step 600/600, loss=0.0986\n",
            "epoch 2/10, step 100/600, loss=0.0542\n",
            "epoch 2/10, step 200/600, loss=0.0751\n",
            "epoch 2/10, step 300/600, loss=0.0742\n",
            "epoch 2/10, step 400/600, loss=0.0210\n",
            "epoch 2/10, step 500/600, loss=0.0471\n",
            "epoch 2/10, step 600/600, loss=0.0348\n",
            "epoch 3/10, step 100/600, loss=0.0730\n",
            "epoch 3/10, step 200/600, loss=0.0823\n",
            "epoch 3/10, step 300/600, loss=0.0401\n",
            "epoch 3/10, step 400/600, loss=0.0233\n",
            "epoch 3/10, step 500/600, loss=0.0281\n",
            "epoch 3/10, step 600/600, loss=0.0828\n",
            "epoch 4/10, step 100/600, loss=0.0737\n",
            "epoch 4/10, step 200/600, loss=0.0526\n",
            "epoch 4/10, step 300/600, loss=0.0045\n",
            "epoch 4/10, step 400/600, loss=0.0358\n",
            "epoch 4/10, step 500/600, loss=0.0961\n",
            "epoch 4/10, step 600/600, loss=0.0045\n",
            "epoch 5/10, step 100/600, loss=0.0185\n",
            "epoch 5/10, step 200/600, loss=0.0124\n",
            "epoch 5/10, step 300/600, loss=0.0050\n",
            "epoch 5/10, step 400/600, loss=0.1079\n",
            "epoch 5/10, step 500/600, loss=0.1034\n",
            "epoch 5/10, step 600/600, loss=0.1227\n",
            "epoch 6/10, step 100/600, loss=0.0186\n",
            "epoch 6/10, step 200/600, loss=0.0239\n",
            "epoch 6/10, step 300/600, loss=0.0072\n",
            "epoch 6/10, step 400/600, loss=0.0526\n",
            "epoch 6/10, step 500/600, loss=0.0871\n",
            "epoch 6/10, step 600/600, loss=0.0039\n",
            "epoch 7/10, step 100/600, loss=0.1252\n",
            "epoch 7/10, step 200/600, loss=0.0281\n",
            "epoch 7/10, step 300/600, loss=0.0707\n",
            "epoch 7/10, step 400/600, loss=0.0066\n",
            "epoch 7/10, step 500/600, loss=0.0373\n",
            "epoch 7/10, step 600/600, loss=0.0413\n",
            "epoch 8/10, step 100/600, loss=0.0582\n",
            "epoch 8/10, step 200/600, loss=0.0057\n",
            "epoch 8/10, step 300/600, loss=0.0010\n",
            "epoch 8/10, step 400/600, loss=0.1358\n",
            "epoch 8/10, step 500/600, loss=0.0421\n",
            "epoch 8/10, step 600/600, loss=0.1137\n",
            "epoch 9/10, step 100/600, loss=0.0784\n",
            "epoch 9/10, step 200/600, loss=0.0413\n",
            "epoch 9/10, step 300/600, loss=0.0129\n",
            "epoch 9/10, step 400/600, loss=0.1990\n",
            "epoch 9/10, step 500/600, loss=0.1186\n",
            "epoch 9/10, step 600/600, loss=0.0243\n",
            "epoch 10/10, step 100/600, loss=0.0051\n",
            "epoch 10/10, step 200/600, loss=0.0199\n",
            "epoch 10/10, step 300/600, loss=0.1152\n",
            "epoch 10/10, step 400/600, loss=0.0867\n",
            "epoch 10/10, step 500/600, loss=0.0343\n",
            "epoch 10/10, step 600/600, loss=0.1742\n"
          ]
        }
      ],
      "source": [
        "#training the network\n",
        "model = convolutionalNet().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate,weight_decay=l1_lambda)\n",
        "totalsteps=len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i,(images,labels) in enumerate(train_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        #forward pass\n",
        "        output=model(images)\n",
        "        l = criterion(output,labels)\n",
        "        #backward pass\n",
        "        optimizer.zero_grad()\n",
        "        l.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5, 2.0)\n",
        "        optimizer.step()\n",
        "        if (i+1)%100==0:\n",
        "            print(f'epoch {epoch+1}/{num_epochs}, step {i+1}/{totalsteps}, loss={l.item():.4f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 97.92 %\n"
          ]
        }
      ],
      "source": [
        "#testing\n",
        "with torch.no_grad():\n",
        "    correct=0;\n",
        "    examples =len(test_loader.dataset)\n",
        "    for images,labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        output = model(images)\n",
        "    \n",
        "     # max returns (output_value ,index)\n",
        "        _, predicted = torch.max(output, 1)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    acc = correct / examples\n",
        "    print(f'Accuracy of the network on the {examples} test images: {100*acc} %')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
