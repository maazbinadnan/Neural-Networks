{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maazbinadnan/Neural-Networks/blob/main/word2veccuda.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42PW4YDOi8M1"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "from numba import cuda\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.corpus import brown\n",
        "import re\n",
        "numberembeddings =10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_XGn_Kx-i8M5",
        "outputId": "fa1d684b-9157-46cd-e287-a31f12e85fa7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['batman', 'superhero', 'appearing', 'american', 'comic', 'books', 'published', 'dc', 'comics', 'character', 'created', 'artist', 'bob', 'kane', 'writer', 'bill', 'finger', 'debuted', '27th', 'issue', 'comic', 'book', 'detective', 'comics', 'march', 'dc', 'universe', 'continuity', 'batman', 'alias', 'bruce', 'wayne', 'wealthy', 'american', 'playboy', 'philanthropist', 'industrialist', 'resides', 'gotham', 'city', \"batman's\", 'origin', 'story', 'features', 'swearing', 'vengeance', 'criminals', 'witnessing', 'murder', 'parents', 'thomas', 'martha', 'child', 'vendetta', 'tempered', 'ideal', 'justice', 'trains', 'physically', 'intellectually', 'crafts', 'bat', 'inspired', 'persona', 'monitors', 'gotham', 'streets', 'night', 'kane', 'finger', 'creators', 'accompanied', 'batman', 'supporting', 'characters', 'including', 'sidekicks', 'robin', 'batgirl', 'allies', 'alfred', 'pennyworth', 'james', 'gordon', 'catwoman', 'foes', 'penguin', 'riddler', 'two', 'face', 'archenemy', 'joker', 'kane', 'conceived', 'batman', 'early', 'capitalize', 'popularity', \"dc's\", 'superman', 'although', 'kane', 'frequently', 'claimed', 'sole', 'creation', 'credit', 'finger', 'substantially', 'developed', 'concept', 'generic', 'superhero', 'something', 'bat', 'like', 'character', 'received', 'spin', 'publication', 'batman', 'batman', 'originally', 'introduced', 'ruthless', 'vigilante', 'frequently', 'killed', 'maimed', 'criminals', 'evolved', 'character', 'stringent', 'moral', 'code', 'strong', 'sense', 'justice', 'unlike', 'superheroes', 'batman', 'possess', 'superpowers', 'instead', 'relying', 'intellect', 'fighting', 'skills', 'wealth', '1960s', 'batman', 'television', 'series', 'used', 'camp', 'aesthetic', 'continued', 'associated', 'character', 'years', 'show', 'ended', 'various', 'creators', 'worked', 'return', 'character', 'darker', 'roots', '1970s', '1980s', 'culminating', 'miniseries', 'dark', 'knight', 'returns', 'frank', 'miller', 'dc', 'featured', 'batman', 'many', 'comic', 'books', 'including', 'comics', 'published', 'imprints', 'vertigo', 'black', 'label', 'longest', 'running', 'batman', 'comic', 'detective', 'comics', 'longest', 'running', 'comic', 'book', 'united', 'states', 'batman', 'frequently', 'depicted', 'alongside', 'dc', 'superheroes', 'superman', 'wonder', 'woman', 'member', 'organizations', 'justice', 'league', 'outsiders', 'addition', 'bruce', 'wayne', 'characters', 'taken', 'batman', 'persona', 'different', 'occasions', 'jean', 'paul', 'valley', 'azrael', 'story', 'arc', 'dick', 'grayson', 'first', 'robin', 'jace', 'fox', 'son', \"wayne's\", 'ally', 'lucius', 'dc', 'also', 'published', 'comics', 'featuring', 'alternate', 'versions', 'batman', 'including', 'incarnation', 'seen', 'dark', 'knight', 'returns', 'successors', 'incarnation', 'flashpoint', 'event', 'numerous', 'interpretations', 'elseworlds', 'stories', 'one', 'iconic', 'characters', 'popular', 'culture', 'batman', 'listed', 'among', 'greatest', 'comic', 'book', 'superheroes', 'fictional', 'characters', 'ever', 'created', 'one', 'commercially', 'successful', 'superheroes', 'likeness', 'licensed', 'featured', 'various', 'media', 'merchandise', 'sold', 'around', 'world', 'includes', 'toy', 'lines', 'lego', 'batman', 'video', 'games', 'like', 'batman', 'arkham', 'series', 'batman', 'adapted', 'live', 'action', 'animated', 'incarnations', 'including', '1960s', 'batman', 'television', 'series', 'played', 'adam', 'west', 'film', 'michael', 'keaton', 'batman', 'batman', 'returns', 'flash', 'val', 'kilmer', 'batman', 'forever', 'george', 'clooney', 'batman', 'robin', 'christian', 'bale', 'dark', 'knight', 'trilogy', 'ben', 'affleck', 'dc', 'extended', 'universe', 'present', 'robert', 'pattinson', 'batman', 'kevin', 'conroy', 'diedrich', 'bader', 'jensen', 'ackles', 'troy', 'baker', 'arnett', 'among', 'others', 'provided', \"character's\", 'voice']\n",
            "361\n"
          ]
        }
      ],
      "source": [
        "corpus =\"Batman is a superhero appearing in American comic books published by DC Comics. The character was created by artist Bob Kane and writer Bill Finger, and debuted in the 27th issue of the comic book Detective Comics on March 30, 1939. In the DC Universe continuity, Batman is the alias of Bruce Wayne, a wealthy American playboy, philanthropist, and industrialist who resides in Gotham City. Batman's origin story features him swearing vengeance against criminals after witnessing the murder of his parents Thomas and Martha as a child, a vendetta tempered with the ideal of justice. He trains himself physically and intellectually, crafts a bat-inspired persona, and monitors the Gotham streets at night. Kane, Finger, and other creators accompanied Batman with supporting characters, including his sidekicks Robin and Batgirl; allies Alfred Pennyworth, James Gordon, and Catwoman; and foes such as the Penguin, the Riddler, Two-Face, and his archenemy, the Joker. Kane conceived Batman in early 1939 to capitalize on the popularity of DC's Superman; although Kane frequently claimed sole creation credit, Finger substantially developed the concept from a generic superhero into something more bat-like. The character received his own spin-off publication, Batman, in 1940. Batman was originally introduced as a ruthless vigilante who frequently killed or maimed criminals, but evolved into a character with a stringent moral code and strong sense of justice. Unlike most superheroes, Batman does not possess any superpowers, instead relying on his intellect, fighting skills, and wealth. The 1960s Batman television series used a camp aesthetic, which continued to be associated with the character for years after the show ended. Various creators worked to return the character to his darker roots in the 1970s and 1980s, culminating with the 1986 miniseries The Dark Knight Returns by Frank Miller.DC has featured Batman in many comic books, including comics published under its imprints such as Vertigo and Black Label. The longest-running Batman comic, Detective Comics, is the longest-running comic book in the United States. Batman is frequently depicted alongside other DC superheroes, such as Superman and Wonder Woman, as a member of organizations such as the Justice League and the Outsiders. In addition to Bruce Wayne, other characters have taken on the Batman persona on different occasions, such as Jean-Paul Valley / Azrael in the 1993–1994 story arc; Dick Grayson, the first Robin, from 2009 to 2011; and Jace Fox, son of Wayne's ally Lucius, as of 2021.[4] DC has also published comics featuring alternate versions of Batman, including the incarnation seen in The Dark Knight Returns and its successors, the incarnation from the Flashpoint (2011) event, and numerous interpretations from Elseworlds stories.One of the most iconic characters in popular culture, Batman has been listed among the greatest comic book superheroes and fictional characters ever created. He is one of the most commercially successful superheroes, and his likeness has been licensed and featured in various media and merchandise sold around the world; this includes toy lines such as Lego Batman and video games like the Batman: Arkham series. Batman has been adapted in live-action and animated incarnations, including the 1960s Batman television series played by Adam West and in film by Michael Keaton in Batman (1989), Batman Returns (1992), and The Flash (2023), Val Kilmer in Batman Forever (1995), George Clooney in Batman and Robin (1997), Christian Bale in The Dark Knight trilogy (2005–2012), Ben Affleck in the DC Extended Universe (2016–present), and Robert Pattinson in The Batman (2022). Kevin Conroy, Diedrich Bader, Jensen Ackles, Troy Baker, and Will Arnett, among others, have provided the character's voice.\"\n",
        "#preprocessing and removing any stopwords\n",
        "def tokenize(text):\n",
        "    pattern = re.compile(r'[A-Za-z]+[\\w^\\']*|[\\w^\\']*[A-Za-z]+[\\w^\\']*')\n",
        "    tokens = pattern.findall(text.lower())\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [token for token in tokens if token not in stop_words]\n",
        "\n",
        "    return tokens\n",
        "\n",
        "text = tokenize(corpus)\n",
        "print(text)\n",
        "print(len(text))\n",
        "vocabsize = len(text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sSi9XEd_i8M7"
      },
      "outputs": [],
      "source": [
        "def mapping(preprocessedtext):\n",
        "    wordtoid=dict()\n",
        "    idtoword=dict()\n",
        "    for i in range(len(preprocessedtext)):\n",
        "        wordtoid[preprocessedtext[i]]=i\n",
        "\n",
        "        idtoword[i]=preprocessedtext[i]\n",
        "    return wordtoid,idtoword\n",
        "wordtoid,idtoword=mapping(text)\n",
        "\n",
        "# print(wordtoid)\n",
        "# print(idtoword)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F8LehfKYi8M7"
      },
      "outputs": [],
      "source": [
        "def one_hot_encode(id, vocab_size):\n",
        "    res = [0] * vocab_size\n",
        "    res[id] = 1\n",
        "    return res\n",
        "\n",
        "def concat(*iterables):\n",
        "    result = []\n",
        "    for iterable in iterables:\n",
        "        result.extend(iterable)\n",
        "    return result\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SiLnb5JRi8M7",
        "outputId": "49a5fb5e-a47c-4471-a896-fbb5f82c9178"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1438, 361)\n",
            "(1438, 361)\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(42)\n",
        "\n",
        "def generate_training_data(tokens, word_to_id, window):\n",
        "    X = []\n",
        "    y = []\n",
        "    n_tokens = len(tokens)\n",
        "\n",
        "    for i in range(n_tokens):\n",
        "        idx = concat(\n",
        "            range(max(0, i - window), i),\n",
        "            range(i, min(n_tokens, i + window + 1))\n",
        "        )\n",
        "        for j in idx:\n",
        "            if i == j:\n",
        "                continue\n",
        "            X.append(one_hot_encode(word_to_id[tokens[i]], len(tokens)))\n",
        "            y.append(one_hot_encode(word_to_id[tokens[j]], len(tokens)))\n",
        "\n",
        "    return np.asarray(X), np.asarray(y)\n",
        "\n",
        "x,y = generate_training_data(text,word_to_id=wordtoid, window=2)\n",
        "print(x.shape)\n",
        "print(y.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sgJQtW8i8M8"
      },
      "source": [
        "defining functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "egIip_Qsi8M9",
        "outputId": "0690f238-c57b-4e18-e500-e4e397b89e35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(42)\n",
        "\n",
        "def init_network(vocabsize,n_embedding):\n",
        "    model={\n",
        "        'W1':np.random.randn(vocabsize,n_embedding),\n",
        "        'W2':np.random.randn(n_embedding,vocabsize)\n",
        "        }\n",
        "    return model\n",
        "model=init_network(vocabsize,numberembeddings)\n",
        "print(model['W1'].shape[1])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5OLHpEChi8M9"
      },
      "outputs": [],
      "source": [
        "def softmax(matrix):\n",
        "    max_val = np.max(matrix, axis=1, keepdims=True)\n",
        "    matrix_exp = np.exp(matrix - max_val)\n",
        "    matrix_sum = np.sum(matrix_exp, axis=1, keepdims=True)\n",
        "    result = matrix_exp / matrix_sum\n",
        "    return result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NnS_9qFji8M-"
      },
      "outputs": [],
      "source": [
        "#forward prop\n",
        "def output(model,X,returncache=True):\n",
        "    cache ={}\n",
        "    cache['z1']=np.dot(X,model['W1'])\n",
        "    cache['z2'] = np.dot(cache[\"z1\"],model[\"W2\"])\n",
        "    cache['probs'] = softmax(cache[\"z2\"])\n",
        "    if not returncache:\n",
        "        return cache['z1']\n",
        "    return cache"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R7xPMHVQi8M-"
      },
      "outputs": [],
      "source": [
        "@cuda.jit\n",
        "def matrix_multiply(A, B, C):\n",
        "    i, j = cuda.grid(2)\n",
        "    if i < C.shape[0] and j < C.shape[1]:\n",
        "        temp = 0.0\n",
        "        for k in range(A.shape[1]):\n",
        "            temp += A[i, k] * B[k, j]\n",
        "        C[i, j] = temp\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BsKE4QwWi8M_"
      },
      "outputs": [],
      "source": [
        "def forwardprop_using_cuda(input_matrix, weight_matrix1, weight_matrix2,returncache=True):\n",
        "    # Transfer input matrices to the GPU\n",
        "    x_input_cuda = cuda.to_device(input_matrix)\n",
        "    w1_input_cuda = cuda.to_device(weight_matrix1)\n",
        "    w2_input_cuda = cuda.to_device(weight_matrix2)\n",
        "\n",
        "    # Create CUDA device arrays for intermediate results\n",
        "    z1_cuda = cuda.device_array((input_matrix.shape[0], weight_matrix1.shape[1]), dtype=np.float64)\n",
        "    z2_cuda = cuda.device_array((input_matrix.shape[0], weight_matrix2.shape[1]), dtype=np.float64)\n",
        "\n",
        "    # Set the block and grid dimensions\n",
        "    threadsperblock = (16, 16)\n",
        "    blockspergrid_x = (input_matrix.shape[0] + threadsperblock[0] - 1) // threadsperblock[0]\n",
        "    blockspergrid_y = (weight_matrix1.shape[1] + threadsperblock[1] - 1) // threadsperblock[1]\n",
        "    blockspergrid = (blockspergrid_x, blockspergrid_y)\n",
        "\n",
        "    # Launch the kernel for the first matrix multiplication\n",
        "    matrix_multiply[blockspergrid, threadsperblock](x_input_cuda, w1_input_cuda, z1_cuda)\n",
        "    cuda.synchronize()\n",
        "    blockspergrid_x = (input_matrix.shape[0] + threadsperblock[0] - 1) // threadsperblock[0]\n",
        "    blockspergrid_y = (weight_matrix2.shape[1] + threadsperblock[1] - 1) // threadsperblock[1]\n",
        "    blockspergrid = (blockspergrid_x, blockspergrid_y)\n",
        "    matrix_multiply[blockspergrid, threadsperblock](z1_cuda, w2_input_cuda, z2_cuda)\n",
        "    cuda.synchronize()\n",
        "\n",
        "    # Copy the final result back to the host\n",
        "    cache = {}\n",
        "    cache['z1'] = z1_cuda.copy_to_host()\n",
        "    cache['z2'] = z2_cuda.copy_to_host()\n",
        "    cache['probs'] = softmax(cache[\"z2\"])\n",
        "    if not returncache:\n",
        "        return cache['probs']\n",
        "    return cache"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Z21Qp7hi8M_"
      },
      "outputs": [],
      "source": [
        "# print(forwardprop_using_cuda(x,model['W1'],model['W2'],False)[9])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTylA-55i8M_"
      },
      "outputs": [],
      "source": [
        "def cross_entropy(z, y, epsilon=1e-10):\n",
        "    z_safe = np.clip(z, epsilon, 1.0 - epsilon)\n",
        "    return -np.sum(np.log(z_safe) * y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBNVGmoki8NA"
      },
      "outputs": [],
      "source": [
        "def backward(model, X, y, alpha):\n",
        "    cache  = forwardprop_using_cuda(X,model['W1'],model['W2'],True)\n",
        "    #cache  = output(model, X)\n",
        "    da2 = cache[\"probs\"] - y\n",
        "    dw2 = cache[\"z1\"].T @ da2\n",
        "    da1 = da2 @ model[\"W2\"].T\n",
        "    dw1 = X.T @ da1\n",
        "    assert(dw2.shape == model[\"W2\"].shape)\n",
        "    assert(dw1.shape == model[\"W1\"].shape)\n",
        "    model[\"W1\"] -= alpha * dw1\n",
        "    model[\"W2\"] -= alpha * dw2\n",
        "    return cross_entropy(cache[\"probs\"], y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dbBeI8Awi8NA"
      },
      "outputs": [],
      "source": [
        "def backward(model, X, y, alpha):\n",
        "    #cache  = forwardprop_using_cuda(X,model['W1'],model['W2'],True)\n",
        "    cache  = output(model, X)\n",
        "    da2 = cache[\"probs\"] - y\n",
        "    dw2 = cache[\"z1\"].T @ da2\n",
        "    da1 = da2 @ model[\"W2\"].T\n",
        "    dw1 = X.T @ da1\n",
        "    assert(dw2.shape == model[\"W2\"].shape)\n",
        "    assert(dw1.shape == model[\"W1\"].shape)\n",
        "    model[\"W1\"] -= alpha * dw1\n",
        "    model[\"W2\"] -= alpha * dw2\n",
        "    return cross_entropy(cache[\"probs\"], y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d3ZQmOtpi8NA",
        "outputId": "8827f7fd-0f95-4a70-e60d-cd4179995bf1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12504\\1503733050.py:4: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
            "  plt.style.use(\"seaborn\")\n"
          ]
        },
        {
          "data": {
            "image/svg+xml": [
              "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
              "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
              "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
              "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"495.604687pt\" height=\"335.465313pt\" viewBox=\"0 0 495.604687 335.465313\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
              " <metadata>\n",
              "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
              "   <cc:Work>\n",
              "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
              "    <dc:date>2023-05-28T13:22:49.430602</dc:date>\n",
              "    <dc:format>image/svg+xml</dc:format>\n",
              "    <dc:creator>\n",
              "     <cc:Agent>\n",
              "      <dc:title>Matplotlib v3.6.2, https://matplotlib.org/</dc:title>\n",
              "     </cc:Agent>\n",
              "    </dc:creator>\n",
              "   </cc:Work>\n",
              "  </rdf:RDF>\n",
              " </metadata>\n",
              " <defs>\n",
              "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
              " </defs>\n",
              " <g id=\"figure_1\">\n",
              "  <g id=\"patch_1\">\n",
              "   <path d=\"M 0 335.465313 \n",
              "L 495.604687 335.465313 \n",
              "L 495.604687 0 \n",
              "L 0 0 \n",
              "z\n",
              "\" style=\"fill: #ffffff\"/>\n",
              "  </g>\n",
              "  <g id=\"axes_1\">\n",
              "   <g id=\"patch_2\">\n",
              "    <path d=\"M 42.004688 312.12 \n",
              "L 488.404687 312.12 \n",
              "L 488.404687 7.2 \n",
              "L 42.004688 7.2 \n",
              "z\n",
              "\" style=\"fill: #eaeaf2\"/>\n",
              "   </g>\n",
              "   <g id=\"matplotlib.axis_1\">\n",
              "    <g id=\"xtick_1\">\n",
              "     <g id=\"line2d_1\">\n",
              "      <path d=\"M 62.295597 312.12 \n",
              "L 62.295597 7.2 \n",
              "\" clip-path=\"url(#pc2758c3b0f)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
              "     </g>\n",
              "     <g id=\"line2d_2\"/>\n",
              "     <g id=\"text_1\">\n",
              "      <!-- 0 -->\n",
              "      <g style=\"fill: #262626\" transform=\"translate(59.515128 326.277813) scale(0.1 -0.1)\">\n",
              "       <defs>\n",
              "        <path id=\"ArialMT-30\" d=\"M 266 2259 \n",
              "Q 266 3072 433 3567 \n",
              "Q 600 4063 929 4331 \n",
              "Q 1259 4600 1759 4600 \n",
              "Q 2128 4600 2406 4451 \n",
              "Q 2684 4303 2865 4023 \n",
              "Q 3047 3744 3150 3342 \n",
              "Q 3253 2941 3253 2259 \n",
              "Q 3253 1453 3087 958 \n",
              "Q 2922 463 2592 192 \n",
              "Q 2263 -78 1759 -78 \n",
              "Q 1097 -78 719 397 \n",
              "Q 266 969 266 2259 \n",
              "z\n",
              "M 844 2259 \n",
              "Q 844 1131 1108 757 \n",
              "Q 1372 384 1759 384 \n",
              "Q 2147 384 2411 759 \n",
              "Q 2675 1134 2675 2259 \n",
              "Q 2675 3391 2411 3762 \n",
              "Q 2147 4134 1753 4134 \n",
              "Q 1366 4134 1134 3806 \n",
              "Q 844 3388 844 2259 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "       </defs>\n",
              "       <use xlink:href=\"#ArialMT-30\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"xtick_2\">\n",
              "     <g id=\"line2d_3\">\n",
              "      <path d=\"M 145.115634 312.12 \n",
              "L 145.115634 7.2 \n",
              "\" clip-path=\"url(#pc2758c3b0f)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
              "     </g>\n",
              "     <g id=\"line2d_4\"/>\n",
              "     <g id=\"text_2\">\n",
              "      <!-- 10 -->\n",
              "      <g style=\"fill: #262626\" transform=\"translate(139.554696 326.277813) scale(0.1 -0.1)\">\n",
              "       <defs>\n",
              "        <path id=\"ArialMT-31\" d=\"M 2384 0 \n",
              "L 1822 0 \n",
              "L 1822 3584 \n",
              "Q 1619 3391 1289 3197 \n",
              "Q 959 3003 697 2906 \n",
              "L 697 3450 \n",
              "Q 1169 3672 1522 3987 \n",
              "Q 1875 4303 2022 4600 \n",
              "L 2384 4600 \n",
              "L 2384 0 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "       </defs>\n",
              "       <use xlink:href=\"#ArialMT-31\"/>\n",
              "       <use xlink:href=\"#ArialMT-30\" x=\"55.615234\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"xtick_3\">\n",
              "     <g id=\"line2d_5\">\n",
              "      <path d=\"M 227.935671 312.12 \n",
              "L 227.935671 7.2 \n",
              "\" clip-path=\"url(#pc2758c3b0f)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
              "     </g>\n",
              "     <g id=\"line2d_6\"/>\n",
              "     <g id=\"text_3\">\n",
              "      <!-- 20 -->\n",
              "      <g style=\"fill: #262626\" transform=\"translate(222.374733 326.277813) scale(0.1 -0.1)\">\n",
              "       <defs>\n",
              "        <path id=\"ArialMT-32\" d=\"M 3222 541 \n",
              "L 3222 0 \n",
              "L 194 0 \n",
              "Q 188 203 259 391 \n",
              "Q 375 700 629 1000 \n",
              "Q 884 1300 1366 1694 \n",
              "Q 2113 2306 2375 2664 \n",
              "Q 2638 3022 2638 3341 \n",
              "Q 2638 3675 2398 3904 \n",
              "Q 2159 4134 1775 4134 \n",
              "Q 1369 4134 1125 3890 \n",
              "Q 881 3647 878 3216 \n",
              "L 300 3275 \n",
              "Q 359 3922 746 4261 \n",
              "Q 1134 4600 1788 4600 \n",
              "Q 2447 4600 2831 4234 \n",
              "Q 3216 3869 3216 3328 \n",
              "Q 3216 3053 3103 2787 \n",
              "Q 2991 2522 2730 2228 \n",
              "Q 2469 1934 1863 1422 \n",
              "Q 1356 997 1212 845 \n",
              "Q 1069 694 975 541 \n",
              "L 3222 541 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "       </defs>\n",
              "       <use xlink:href=\"#ArialMT-32\"/>\n",
              "       <use xlink:href=\"#ArialMT-30\" x=\"55.615234\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"xtick_4\">\n",
              "     <g id=\"line2d_7\">\n",
              "      <path d=\"M 310.755708 312.12 \n",
              "L 310.755708 7.2 \n",
              "\" clip-path=\"url(#pc2758c3b0f)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
              "     </g>\n",
              "     <g id=\"line2d_8\"/>\n",
              "     <g id=\"text_4\">\n",
              "      <!-- 30 -->\n",
              "      <g style=\"fill: #262626\" transform=\"translate(305.19477 326.277813) scale(0.1 -0.1)\">\n",
              "       <defs>\n",
              "        <path id=\"ArialMT-33\" d=\"M 269 1209 \n",
              "L 831 1284 \n",
              "Q 928 806 1161 595 \n",
              "Q 1394 384 1728 384 \n",
              "Q 2125 384 2398 659 \n",
              "Q 2672 934 2672 1341 \n",
              "Q 2672 1728 2419 1979 \n",
              "Q 2166 2231 1775 2231 \n",
              "Q 1616 2231 1378 2169 \n",
              "L 1441 2663 \n",
              "Q 1497 2656 1531 2656 \n",
              "Q 1891 2656 2178 2843 \n",
              "Q 2466 3031 2466 3422 \n",
              "Q 2466 3731 2256 3934 \n",
              "Q 2047 4138 1716 4138 \n",
              "Q 1388 4138 1169 3931 \n",
              "Q 950 3725 888 3313 \n",
              "L 325 3413 \n",
              "Q 428 3978 793 4289 \n",
              "Q 1159 4600 1703 4600 \n",
              "Q 2078 4600 2393 4439 \n",
              "Q 2709 4278 2876 4000 \n",
              "Q 3044 3722 3044 3409 \n",
              "Q 3044 3113 2884 2869 \n",
              "Q 2725 2625 2413 2481 \n",
              "Q 2819 2388 3044 2092 \n",
              "Q 3269 1797 3269 1353 \n",
              "Q 3269 753 2831 336 \n",
              "Q 2394 -81 1725 -81 \n",
              "Q 1122 -81 723 278 \n",
              "Q 325 638 269 1209 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "       </defs>\n",
              "       <use xlink:href=\"#ArialMT-33\"/>\n",
              "       <use xlink:href=\"#ArialMT-30\" x=\"55.615234\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"xtick_5\">\n",
              "     <g id=\"line2d_9\">\n",
              "      <path d=\"M 393.575745 312.12 \n",
              "L 393.575745 7.2 \n",
              "\" clip-path=\"url(#pc2758c3b0f)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
              "     </g>\n",
              "     <g id=\"line2d_10\"/>\n",
              "     <g id=\"text_5\">\n",
              "      <!-- 40 -->\n",
              "      <g style=\"fill: #262626\" transform=\"translate(388.014808 326.277813) scale(0.1 -0.1)\">\n",
              "       <defs>\n",
              "        <path id=\"ArialMT-34\" d=\"M 2069 0 \n",
              "L 2069 1097 \n",
              "L 81 1097 \n",
              "L 81 1613 \n",
              "L 2172 4581 \n",
              "L 2631 4581 \n",
              "L 2631 1613 \n",
              "L 3250 1613 \n",
              "L 3250 1097 \n",
              "L 2631 1097 \n",
              "L 2631 0 \n",
              "L 2069 0 \n",
              "z\n",
              "M 2069 1613 \n",
              "L 2069 3678 \n",
              "L 634 1613 \n",
              "L 2069 1613 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "       </defs>\n",
              "       <use xlink:href=\"#ArialMT-34\"/>\n",
              "       <use xlink:href=\"#ArialMT-30\" x=\"55.615234\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"xtick_6\">\n",
              "     <g id=\"line2d_11\">\n",
              "      <path d=\"M 476.395782 312.12 \n",
              "L 476.395782 7.2 \n",
              "\" clip-path=\"url(#pc2758c3b0f)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
              "     </g>\n",
              "     <g id=\"line2d_12\"/>\n",
              "     <g id=\"text_6\">\n",
              "      <!-- 50 -->\n",
              "      <g style=\"fill: #262626\" transform=\"translate(470.834845 326.277813) scale(0.1 -0.1)\">\n",
              "       <defs>\n",
              "        <path id=\"ArialMT-35\" d=\"M 266 1200 \n",
              "L 856 1250 \n",
              "Q 922 819 1161 601 \n",
              "Q 1400 384 1738 384 \n",
              "Q 2144 384 2425 690 \n",
              "Q 2706 997 2706 1503 \n",
              "Q 2706 1984 2436 2262 \n",
              "Q 2166 2541 1728 2541 \n",
              "Q 1456 2541 1237 2417 \n",
              "Q 1019 2294 894 2097 \n",
              "L 366 2166 \n",
              "L 809 4519 \n",
              "L 3088 4519 \n",
              "L 3088 3981 \n",
              "L 1259 3981 \n",
              "L 1013 2750 \n",
              "Q 1425 3038 1878 3038 \n",
              "Q 2478 3038 2890 2622 \n",
              "Q 3303 2206 3303 1553 \n",
              "Q 3303 931 2941 478 \n",
              "Q 2500 -78 1738 -78 \n",
              "Q 1113 -78 717 272 \n",
              "Q 322 622 266 1200 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "       </defs>\n",
              "       <use xlink:href=\"#ArialMT-35\"/>\n",
              "       <use xlink:href=\"#ArialMT-30\" x=\"55.615234\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "   </g>\n",
              "   <g id=\"matplotlib.axis_2\">\n",
              "    <g id=\"ytick_1\">\n",
              "     <g id=\"line2d_13\">\n",
              "      <path d=\"M 42.004688 262.183788 \n",
              "L 488.404687 262.183788 \n",
              "\" clip-path=\"url(#pc2758c3b0f)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
              "     </g>\n",
              "     <g id=\"line2d_14\"/>\n",
              "     <g id=\"text_7\">\n",
              "      <!-- 15000 -->\n",
              "      <g style=\"fill: #262626\" transform=\"translate(7.2 265.762694) scale(0.1 -0.1)\">\n",
              "       <use xlink:href=\"#ArialMT-31\"/>\n",
              "       <use xlink:href=\"#ArialMT-35\" x=\"55.615234\"/>\n",
              "       <use xlink:href=\"#ArialMT-30\" x=\"111.230469\"/>\n",
              "       <use xlink:href=\"#ArialMT-30\" x=\"166.845703\"/>\n",
              "       <use xlink:href=\"#ArialMT-30\" x=\"222.460938\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"ytick_2\">\n",
              "     <g id=\"line2d_15\">\n",
              "      <path d=\"M 42.004688 195.190236 \n",
              "L 488.404687 195.190236 \n",
              "\" clip-path=\"url(#pc2758c3b0f)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
              "     </g>\n",
              "     <g id=\"line2d_16\"/>\n",
              "     <g id=\"text_8\">\n",
              "      <!-- 20000 -->\n",
              "      <g style=\"fill: #262626\" transform=\"translate(7.2 198.769142) scale(0.1 -0.1)\">\n",
              "       <use xlink:href=\"#ArialMT-32\"/>\n",
              "       <use xlink:href=\"#ArialMT-30\" x=\"55.615234\"/>\n",
              "       <use xlink:href=\"#ArialMT-30\" x=\"111.230469\"/>\n",
              "       <use xlink:href=\"#ArialMT-30\" x=\"166.845703\"/>\n",
              "       <use xlink:href=\"#ArialMT-30\" x=\"222.460938\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"ytick_3\">\n",
              "     <g id=\"line2d_17\">\n",
              "      <path d=\"M 42.004688 128.196683 \n",
              "L 488.404687 128.196683 \n",
              "\" clip-path=\"url(#pc2758c3b0f)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
              "     </g>\n",
              "     <g id=\"line2d_18\"/>\n",
              "     <g id=\"text_9\">\n",
              "      <!-- 25000 -->\n",
              "      <g style=\"fill: #262626\" transform=\"translate(7.2 131.77559) scale(0.1 -0.1)\">\n",
              "       <use xlink:href=\"#ArialMT-32\"/>\n",
              "       <use xlink:href=\"#ArialMT-35\" x=\"55.615234\"/>\n",
              "       <use xlink:href=\"#ArialMT-30\" x=\"111.230469\"/>\n",
              "       <use xlink:href=\"#ArialMT-30\" x=\"166.845703\"/>\n",
              "       <use xlink:href=\"#ArialMT-30\" x=\"222.460938\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"ytick_4\">\n",
              "     <g id=\"line2d_19\">\n",
              "      <path d=\"M 42.004688 61.203131 \n",
              "L 488.404687 61.203131 \n",
              "\" clip-path=\"url(#pc2758c3b0f)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
              "     </g>\n",
              "     <g id=\"line2d_20\"/>\n",
              "     <g id=\"text_10\">\n",
              "      <!-- 30000 -->\n",
              "      <g style=\"fill: #262626\" transform=\"translate(7.2 64.782037) scale(0.1 -0.1)\">\n",
              "       <use xlink:href=\"#ArialMT-33\"/>\n",
              "       <use xlink:href=\"#ArialMT-30\" x=\"55.615234\"/>\n",
              "       <use xlink:href=\"#ArialMT-30\" x=\"111.230469\"/>\n",
              "       <use xlink:href=\"#ArialMT-30\" x=\"166.845703\"/>\n",
              "       <use xlink:href=\"#ArialMT-30\" x=\"222.460938\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "   </g>\n",
              "   <g id=\"line2d_21\">\n",
              "    <path d=\"M 62.295597 263.263553 \n",
              "L 70.5776 298.26 \n",
              "L 78.859604 164.867605 \n",
              "L 87.141608 101.403896 \n",
              "L 95.423611 50.615723 \n",
              "L 103.705615 21.06 \n",
              "L 111.987619 21.06 \n",
              "L 120.269623 25.996267 \n",
              "L 128.551626 24.453684 \n",
              "L 136.83363 28.772918 \n",
              "L 145.115634 31.549568 \n",
              "L 153.397637 28.464401 \n",
              "L 161.679641 28.155884 \n",
              "L 169.961645 42.65617 \n",
              "L 178.243649 43.58172 \n",
              "L 186.525652 21.98555 \n",
              "L 194.807656 47.28392 \n",
              "L 203.08966 21.98555 \n",
              "L 211.371663 21.98555 \n",
              "L 219.653667 43.58172 \n",
              "L 227.935671 22.602584 \n",
              "L 236.217675 22.294067 \n",
              "L 244.499678 46.666887 \n",
              "L 252.781682 22.602584 \n",
              "L 261.063686 21.98555 \n",
              "L 269.345689 45.741337 \n",
              "L 277.627693 27.847368 \n",
              "L 285.909697 25.070717 \n",
              "L 294.1917 46.35837 \n",
              "L 302.473704 46.975404 \n",
              "L 310.755708 21.98555 \n",
              "L 319.037712 45.741337 \n",
              "L 327.319715 21.98555 \n",
              "L 335.601719 21.98555 \n",
              "L 343.883723 47.28392 \n",
              "L 352.165726 23.219617 \n",
              "L 360.44773 24.145167 \n",
              "L 368.729734 46.35837 \n",
              "L 377.011738 46.975404 \n",
              "L 385.293741 21.98555 \n",
              "L 393.575745 46.666887 \n",
              "L 401.857749 21.98555 \n",
              "L 410.139752 21.98555 \n",
              "L 418.421756 43.58172 \n",
              "L 426.70376 22.9111 \n",
              "L 434.985764 23.219617 \n",
              "L 443.267767 47.28392 \n",
              "L 451.549771 23.219617 \n",
              "L 459.831775 23.219617 \n",
              "L 468.113778 42.65617 \n",
              "\" clip-path=\"url(#pc2758c3b0f)\" style=\"fill: none; stroke: #87ceeb; stroke-width: 1.75; stroke-linecap: round\"/>\n",
              "   </g>\n",
              "   <g id=\"patch_3\">\n",
              "    <path d=\"M 42.004688 312.12 \n",
              "L 42.004688 7.2 \n",
              "\" style=\"fill: none\"/>\n",
              "   </g>\n",
              "   <g id=\"patch_4\">\n",
              "    <path d=\"M 488.404687 312.12 \n",
              "L 488.404687 7.2 \n",
              "\" style=\"fill: none\"/>\n",
              "   </g>\n",
              "   <g id=\"patch_5\">\n",
              "    <path d=\"M 42.004687 312.12 \n",
              "L 488.404687 312.12 \n",
              "\" style=\"fill: none\"/>\n",
              "   </g>\n",
              "   <g id=\"patch_6\">\n",
              "    <path d=\"M 42.004687 7.2 \n",
              "L 488.404687 7.2 \n",
              "\" style=\"fill: none\"/>\n",
              "   </g>\n",
              "  </g>\n",
              " </g>\n",
              " <defs>\n",
              "  <clipPath id=\"pc2758c3b0f\">\n",
              "   <rect x=\"42.004688\" y=\"7.2\" width=\"446.4\" height=\"304.92\"/>\n",
              "  </clipPath>\n",
              " </defs>\n",
              "</svg>\n"
            ],
            "text/plain": [
              "<Figure size 800x550 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'svg'\n",
        "plt.style.use(\"seaborn\")\n",
        "\n",
        "n_iter = 50\n",
        "learning_rate = 0.05\n",
        "\n",
        "history = [backward(model, x, y, learning_rate) for _ in range(n_iter)]\n",
        "\n",
        "plt.plot(range(len(history)), history, color=\"skyblue\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oNQLcBHDi8NA",
        "outputId": "8ca4a5c6-255e-4056-b531-9a471188d46d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "batman\n",
            "superhero\n",
            "dc\n",
            "comic\n",
            "appearing\n",
            "comics\n",
            "books\n",
            "character\n",
            "american\n",
            "published\n"
          ]
        }
      ],
      "source": [
        "learning = one_hot_encode(wordtoid[\"batman\"], len(text))\n",
        "result = output(model, [learning],False)[0]\n",
        "\n",
        "for word in (idtoword[id] for id in np.argsort(result)[::-1]):\n",
        "    print(word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xOcD3hGti8NA",
        "outputId": "3fcb4807-f2a1-47a6-edf5-664d25e351db"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package brown to\n",
            "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\HP\\Dropbox\\maaz iba work\\Iba\\semester 6\\DeepL\\myneuralnetworks\\Neural-Networks\\word2veccuda.ipynb Cell 18\u001b[0m in \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/HP/Dropbox/maaz%20iba%20work/Iba/semester%206/DeepL/myneuralnetworks/Neural-Networks/word2veccuda.ipynb#X24sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m# Create word_to_index mapping\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/HP/Dropbox/maaz%20iba%20work/Iba/semester%206/DeepL/myneuralnetworks/Neural-Networks/word2veccuda.ipynb#X24sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m word_to_index \u001b[39m=\u001b[39m {}\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/HP/Dropbox/maaz%20iba%20work/Iba/semester%206/DeepL/myneuralnetworks/Neural-Networks/word2veccuda.ipynb#X24sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mfor\u001b[39;00m sentence \u001b[39min\u001b[39;00m sentences:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/HP/Dropbox/maaz%20iba%20work/Iba/semester%206/DeepL/myneuralnetworks/Neural-Networks/word2veccuda.ipynb#X24sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m sentence:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/HP/Dropbox/maaz%20iba%20work/Iba/semester%206/DeepL/myneuralnetworks/Neural-Networks/word2veccuda.ipynb#X24sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m         \u001b[39mif\u001b[39;00m word \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m word_to_index:\n",
            "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\nltk\\corpus\\reader\\util.py:424\u001b[0m, in \u001b[0;36mConcatenatedCorpusView.iterate_from\u001b[1;34m(self, start_tok)\u001b[0m\n\u001b[0;32m    421\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_open_piece \u001b[39m=\u001b[39m piece\n\u001b[0;32m    423\u001b[0m \u001b[39m# Get everything we can from this piece.\u001b[39;00m\n\u001b[1;32m--> 424\u001b[0m \u001b[39myield from\u001b[39;00m piece\u001b[39m.\u001b[39miterate_from(\u001b[39mmax\u001b[39m(\u001b[39m0\u001b[39m, start_tok \u001b[39m-\u001b[39m offset))\n\u001b[0;32m    426\u001b[0m \u001b[39m# Update the offset table.\u001b[39;00m\n\u001b[0;32m    427\u001b[0m \u001b[39mif\u001b[39;00m piecenum \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_offsets):\n",
            "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\nltk\\corpus\\reader\\util.py:312\u001b[0m, in \u001b[0;36mStreamBackedCorpusView.iterate_from\u001b[1;34m(self, start_tok)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(tokens, (\u001b[39mtuple\u001b[39m, \u001b[39mlist\u001b[39m, AbstractLazySequence)), (\n\u001b[0;32m    308\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mblock reader \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m() should return list or tuple.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    309\u001b[0m     \u001b[39m%\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mread_block\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[0;32m    310\u001b[0m )\n\u001b[0;32m    311\u001b[0m num_toks \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(tokens)\n\u001b[1;32m--> 312\u001b[0m new_filepos \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stream\u001b[39m.\u001b[39;49mtell()\n\u001b[0;32m    313\u001b[0m \u001b[39massert\u001b[39;00m (\n\u001b[0;32m    314\u001b[0m     new_filepos \u001b[39m>\u001b[39m filepos\n\u001b[0;32m    315\u001b[0m ), \u001b[39m\"\u001b[39m\u001b[39mblock reader \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m() should consume at least 1 byte (filepos=\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (\n\u001b[0;32m    316\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mread_block\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m,\n\u001b[0;32m    317\u001b[0m     filepos,\n\u001b[0;32m    318\u001b[0m )\n\u001b[0;32m    320\u001b[0m \u001b[39m# Update our cache.\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\nltk\\data.py:1303\u001b[0m, in \u001b[0;36mSeekableUnicodeStreamReader.tell\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1301\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstream\u001b[39m.\u001b[39mseek(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_rewind_checkpoint)\n\u001b[0;32m   1302\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_char_seek_forward(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_rewind_numchars, est_bytes)\n\u001b[1;32m-> 1303\u001b[0m filepos \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstream\u001b[39m.\u001b[39;49mtell()\n\u001b[0;32m   1305\u001b[0m \u001b[39m# Sanity check\u001b[39;00m\n\u001b[0;32m   1306\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mDEBUG:\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import nltk\n",
        "from torch.utils.data import DataLoader\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Download the Brown corpus from NLTK\n",
        "nltk.download('brown')\n",
        "\n",
        "# Load the Brown corpus\n",
        "from nltk.corpus import brown\n",
        "sentences = brown.sents()\n",
        "\n",
        "# Create word_to_index mapping\n",
        "word_to_index = {}\n",
        "for sentence in sentences:\n",
        "    for word in sentence:\n",
        "        if word not in word_to_index:\n",
        "            word_to_index[word] = len(word_to_index)\n",
        "\n",
        "# Convert sentences to word indices\n",
        "word_indices = [[word_to_index[word] for word in sentence] for sentence in sentences]\n",
        "\n",
        "# Set device to CUDA if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Define the Word2Vec model architecture\n",
        "class Word2VecModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim):\n",
        "        super(Word2VecModel, self).__init__()\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        embeds = self.embeddings(inputs)\n",
        "        return embeds\n",
        "\n",
        "# Define model parameters\n",
        "vocab_size = len(word_to_index)\n",
        "embedding_dim = 100\n",
        "num_epochs = 10\n",
        "\n",
        "# Create DataLoader for batching and shuffling\n",
        "dataloader = DataLoader(word_indices, batch_size=128, shuffle=True)\n",
        "\n",
        "# Create Word2Vec model\n",
        "model = Word2VecModel(vocab_size, embedding_dim).to(device)\n",
        "\n",
        "# Training loop\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "for epoch in range(num_epochs):\n",
        "    for batch in dataloader:\n",
        "        batch = batch.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        embeddings = model(batch)\n",
        "        targets = batch.view(-1)\n",
        "        loss = criterion(embeddings.view(-1, vocab_size), targets)\n",
        "\n",
        "        # Backward pass and update model weights\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# Save the trained model\n",
        "torch.save(model.state_dict(), 'word2vec_model_cuda.pth')\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}